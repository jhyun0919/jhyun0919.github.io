<!DOCTYPE html>
<html class="no-js">
<head>
	<meta charset="utf-8">
	<title>Search | Park's Archive</title>
	<meta name="description"
		content="A website with blog posts and pages">
	<meta name="viewport" content="width=device-width, initial-scale=1">

	<!-- CSS -->
	<link rel="stylesheet" href="/assets/css/main.css">

	<!--Favicon-->
	<link rel="shortcut icon" href="/assets/favicon.ico" type="image/x-icon">

	<!-- Canonical -->
	<link rel="canonical" href="/search.html">

	<!-- RSS -->
	<link rel="alternate" type="application/atom+xml" title="Park's Archive"
		href="/feed.xml" />

	<!-- Font Awesome -->
	<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.8.2/css/all.css"
		integrity="sha384-oS3vJWv+0UjzBfQzYUhtDYW+Pj2yciDJxpsK1OYPAYjqT085Qq/1cq5FLXAZQ7Ay" crossorigin="anonymous">

	<!-- Google Fonts -->
	
	<link href="//fonts.googleapis.com/css?family=Source+Sans+Pro:400,700,700italic,400italic" rel="stylesheet"
		type="text/css">
	

	<!-- KaTeX -->
	

	<!-- Google Analytics -->
	
	<script>
		(function (i, s, o, g, r, a, m) {
		i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
			(i[r].q = i[r].q || []).push(arguments)
		}, i[r].l = 1 * new Date(); a = s.createElement(o),
			m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
		})(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

		ga('create', 'UA-151012240-1', 'auto');
		ga('send', 'pageview');
	</script>
	
</head>
<header class="site-header">
	<div class="branding">
		
		<h1 class="site-title">
			<a href="/">Park's Archive</a>
		</h1>

		<nav class="site-nav">
			<ul>
				
				

				<!-- Search bar -->
				
				<li>
					<form action="/search.html" method="get">
						<input type="text" id="search-box" name="query" placeholder="Search" class="">
						<button type="submit" class="">
							<i class="fa fa-fw fa-search"></i>
						</button>
					</form>
				</li>
				

				<!-- Social icons from Font Awesome, ifenabled  -->
				
<li>
	<a href="/feed.xml" title="Follow RSS feed">
		<i class="fas fa-fw fa-rss"></i>
	</a>
</li>



<li>
	<a href="mailto:jhyun0919@utexas.edu" title="Email">
		<i class="fas fa-fw fa-envelope"></i>
	</a>
</li>









<li>
	<a href="https://www.facebook.com/park.jhyun0919" title="Follow on Facebook">
		<i class="fab fa-fw fa-facebook"></i>
	</a>
</li>





<li>
	<a href="https://github.com/jhyun0919" title="Follow on GitHub">
		<i class="fab fa-fw fa-github"></i>
	</a>
</li>





<li>
	<a href="http://instagram.com/park._.shape" title="Follow on Instagram">
		<i class="fab fa-fw fa-instagram"></i>
	</a>
</li>



<li>
	<a href="https://www.linkedin.com/in/jhyun0919/" title="Follow on LinkedIn">
		<i class="fab fa-fw fa-linkedin"></i>
	</a>
</li>
























			</ul>
		</nav>
	</div>

	<div class="site-category">
		<ul class='cat1'>
			<li>
				<a href="/">Home</a>
			</li>

			<li>
				<a href="/">Research</a>
				<ul>
					<li>
						<a href="/Research/CS">CS</a>
					</li>
					<li>
						<a href="/Research/Meeting Log">Dr. Zhu's Group Meeting</a>
					</li>
					<li>
						<a href="/Research/Energy">Energy</a>
					</li>
					<li>
						<a href="/Research/Mathematics">Mathematics</a>
					</li>
					<li>
						<a href="/Research/ML&DL">ML & DL</a>
					</li>
					<li>
						<a href="/Research/RL">RL</a>
					</li>
				</ul>
			</li>

			<li>
				<a href="/">Daily</a>
				<ul>
					<li>
						<a href="/Daily/Essay">Essay</a>
					</li>
					<li>
						<a href="/Daily/Travel">Travel</a>
					</li>
				</ul>
			</li>

			<li>
				<a href="/about">About</a>
			</li>


		</ul>
	</div>

</header>

<body>
  <div class="content">
    <article >
  <header style="background-image: url('/')">
    <h1 class="title">Search</h1>
    
  </header>
  <section class="post-content"><div class="search">
    <div id="search-results"></div>
    <p id="not-found" style="display: none">
        No results found.
    </p>
</div>


<script>
  window.store = {
    
      "research-meeting-20log-2021-04-16-dr-zhu-group-meeting-log-html": {
        "title": "Dr. Zhu's Group Meeting Log",
        "tags": "Group Meeting",
        "date": "April 16, 2021",
        "author": "",
        "category": "",
        "content": "Speech Title: Grid-Aware Machine Learning for Distribution System Modeling, Monitoring, and OptimizationThe contents covered in this article are credited to the speaker of the meeting, Dr. Zhu, and her research group members.TL; DRSpeaker  Shanny Lin  Abstract or Short BriefKeywords  modeling, monitoring, optimization  partial observability  CVaRGroup Meeting RecapMotivation  Problem Formulation  How to estimate an accurate model of the power system?  How to address monitoring and optimization tasks under limited observability? Proposed ApproachModeling  Linearized distribution flow model\\[\\begin{aligned}\\mathbf{v} &amp; \\approx \\mathbf{Rp} + \\mathbf{Xq} \\\\&amp; = \\mathbf{M}^{-T}\\mathbf{D}_{r}\\mathbf{M}^{-1}\\mathbf{p} + \\mathbf{M}^{-T}\\mathbf{D}_{x}\\mathbf{M}^{-1}\\mathbf{q}\\end{aligned}\\tag{1}\\]  Bi-linear regression with Group-LASSO regularization\\[\\min_{\\mathbf{\\theta}, \\{\\tilde{\\mathbf{s}}^{\\mathcal{U}}_{t}\\}}{\\sum_{t}^{T}{\\| \\tilde{\\mathbf{v}}_t} - \\mathbf{A}(\\tilde{\\mathbf{s}}^{\\mathcal{O}}_{t})\\mathbf{\\theta} - \\mathbf{A}(\\tilde{\\mathbf{s}}^{\\mathcal{U}}_{t})\\mathbf{\\theta} \\|_2^2 + \\lambda \\| \\tilde{\\mathbf{s}}^{\\mathcal{U}}_{t} \\|_G}\\tag{2}\\]  Alternating Minimization (AM)          between $\\mathbf{\\theta}$ and ${\\tilde{\\mathbf{s}}^{\\mathcal{U}}_{t}}$      Monitoring  DER visibility by leveraging heterogenous &amp; dynamic data.          Smart meter data ($\\mathbf{\\Gamma}$)      D-PMU data ($\\mathbf{Z}$)        Spatio-temporal learning\\[\\begin{aligned}\\begin{bmatrix} \\mathbf{P} \\\\ \\mathbf{Q} \\end{bmatrix} &amp;= \\mathbf{L} + \\mathbf{DU} \\\\&amp; = \\mathbf{L} + \\begin{bmatrix} \\mathbf{D}^{P} \\\\ \\mathbf{D}^{Q} \\end{bmatrix}\\end{aligned}\\tag{3}\\]\\[\\begin{aligned}\\min&amp;_{\\mathbf{L}, \\mathbf{D}}{\\|\\mathbf{L}\\|_{*} + \\lambda\\|\\mathbf{D}\\|_{G}} \\\\&amp; \\text{s.to } \\mathbf{L} + \\mathbf{D}\\mathbf{U} \\text{ satisfies error bound for } \\mathbf{\\Gamma} \\text{ and } \\mathbf{Z}\\end{aligned}\\tag{4}\\]\\[\\begin{aligned}\\min&amp;_{\\mathbf{v}, \\mathbf{D}}{\\frac{1}{2} \\|\\mathbf{v}\\|_{2}^{2} + \\lambda\\|\\mathbf{D}\\|_{G}}\\\\&amp; \\text{s.to } \\mathbf{uv^{T}} + \\mathbf{D}\\mathbf{U} \\text{ satisfies error bound for } \\mathbf{\\Gamma} \\text{ and } \\mathbf{Z}\\end{aligned}\\tag{5}\\]Optimization  DER optimization\\[\\begin{aligned}\\mathbf{\\hat{q}} = &amp; \\min_{\\mathbf{q} \\in \\mathcal{Q}}{Losses(\\mathbf{q})} \\\\&amp; \\text{s.to } \\begin{bmatrix} \\mathbf{Xq} + \\mathbf{y} - \\mathbf{\\bar{v}} \\\\ -\\mathbf{Xq} - \\mathbf{y} + \\mathbf{\\underline{v}} \\end{bmatrix} \\leq\\mathbf{0}\\end{aligned}\\tag{6}\\]  Graph learning\\[\\min_{\\Phi}{Avg(\\| \\Phi(\\mathbf{z}) -  \\mathbf{\\hat{q}}\\|_{2}^{2})}\\tag{7}\\]\\[\\mathbf{z}_{l+1} = \\sigma(\\mathbf{W}_l\\mathbf{z}_l\\mathbf{H}_l + \\mathbf{b}_l)\\tag{8}\\]  Conditional Value-at-Risk (CVaR) method.Experiment &amp; ResultModeling  Line reactance estimationMonitoring  DER visibilityOptimization  Graph learning vs. Local learningFuture Study  What I BenefitRegularizationLasso and Ridge Regressions []Given a dataset ${X,y}$ where $X$ is the feature and $y$ is the label for regression, we simply model it as has a linear relationship $y = X\\beta$. With regularization, we can control the degree of freedom of the model parameter ($\\beta$) and able to avoid the risk of overfitting.The two representative regularizations are LASSO (L1) and Ridge (L2), and they are defined as follows.\\[\\beta^{*} = \\underset{\\beta}{\\mathrm{argmin}} {\\| y - X\\beta \\|_2^2} + \\lambda \\| \\beta \\|_{1}\\]\\[\\beta^{*} = \\underset{\\beta}{\\mathrm{argmin}} {\\| y - X\\beta \\|_2^2} + \\lambda \\| \\beta \\|_{2}\\]Due to the shape of their constraints boundary (norm ball shape), LASSO encourage a sparse result as a solution of the optimal problem.   Figure . Conventional Explanation to Sparsity Caused by Lasso. []  Group LASSOSuppose the weights in $\\beta$ could be grouped, the new weight vector becomes $\\beta_G = { \\beta^{(1)}, \\beta^{(2)},⋯,\\beta^{(m)} }$. Each $\\beta^{(l)}$ for $1 \\leq l \\leq m$ represents a group of weights from $\\beta$.We further group $X$ accordingly. We denote $X(l)$ as the submatrix of $X$ with columns corresponding to the weights in $\\beta^{(l)}$. The optimization problem becomes\\[\\beta^{*} = \\underset{\\beta}{\\mathrm{argmin}} {\\| y - \\sum_{l=1}^{m}{X^{(l)}\\beta^{(l)}} \\|_2^2} + \\lambda \\sum_{l=1}^{m} \\sqrt{p_{l}}\\| \\beta^{(l)} \\|_{1}\\]where $p^{(l)}$ represents the number of weights in $\\beta^{(l)}$.Why do we need GROUPING?Usually, the variables of the minimization problem are not correlated. However, when there are certain constraints or correlation between variables, we need to group them appropriately.The power injections as minimization variables, covered in the presentation , is a good example. Since power is comprised of active and reactive power, the variable of the minimization problem of Eq. (2) has to be grouped as follows.\\[\\tilde{\\mathbf{s}}_{t}\\ = \\begin{bmatrix} \\tilde{p}_n &amp; \\tilde{q}_n \\end{bmatrix}\\]CVaRThrow back the QuestionWhat I ContributeThe framework of research/study  Motivation    Problem Formulation    Proposed Approach    Experiment &amp; Result    Future Study  The above list is the framework of research that Dr. Zhu discussed at the start of this year. Almost all research papers have been written along this process, which is also the basic step of our research.However, it was not easy for me to summarize the contents of today’s meeting with this framework since there are three main topics in a single speech. From my point of view, one of each topic is good enough for one individual presentation, and it would have been easier for me to fit the contents into this framework.Therefore, I strongly suggest conducting our research and preparing our speech with this framework; then, it will help us draw better results in our research and deliver the main points more clearly to others.Resting   Figure . Decanting Guide []  It is said that decanting is necessary to enjoy wine in it’s best quality. Likewise, our slides do want to have resting.References[] L. Mao, “Group Lasso,” Lei Mao’s Log Book. [Online]. Available: https://leimao.github.io/blog/Group-Lasso/. [Accessed: 17-Apr-2021].[] “Lasso (statistics),” Wikipedia, 14-Apr-2021. [Online]. Available: https://en.wikipedia.org/wiki/Lasso_(statistics). [Accessed: 17-Apr-2021].[] P. P. H. Winston, “How to Speak,” MIT OpenCourseWare. [Online]. Available: https://ocw.mit.edu/resources/res-tll-005-how-to-speak-january-iap-2018/. [Accessed: 17-Apr-2021].[] E. Golman, “The Ultimate Guide to Decanting &amp; Aerating Kosher Wine,” Kosherwine.com, 18-Dec-2020. [Online]. Available: https://www.kosherwine.com/discover/the-ultimate-guide-to-decanting-kosher-wine. [Accessed: 17-Apr-2021].[]",
        "url": "//research/meeting%20log/2021/04/16/Dr-Zhu-Group-Meeting-Log.html"
      }
      ,
    
      "research-ml-dl-2021-04-14-stgcn-html": {
        "title": "(Research Proj) Spatio-Temporal Graph Convolutional Networks",
        "tags": "GCN, STGCN, Research Proj, Paper review",
        "date": "April 14, 2021",
        "author": "",
        "category": "",
        "content": "This article is about a review of the paper [1], and is the second part of a personal research project to utilize the use of Graph Neural Network to the field of cascading outage prediction or detection.I plan to utilize the model architecture used in this paper for cascading outage prediction.  Research Project’s Git Repository1. INTRODUCTION1.1. What is the problem?Transportation plays a vital role in everybody’s daily life. According to a survey in 2015, U.S. drivers spend about 48 minutes on average behind the wheel daily [2]. Under this circumstance, an accurate real-time forecast of traffic conditions is of paramount importance for road users, private sectors, and governments.There were many efforts to monitor the current status of traffic conditions and to predict the future. These studies aimed to contribute to widely used transportation services, such as flow control, route planning, and navigation.1.2. History of previous approachesPrevious studies on traffic prediction can be roughly divided into two categories: Dynamical modeling and Data-driven methods.Many researchers are shifting their attention to data-driven approaches, since dynamical modeling methods have drawbacks as follow. 😡  It requires sophisticated systematic programming.   It consumes massive computational power.   Impractical assumptions and simplifications among the modeling degrade the prediction accuracy. As a result, Deep learning approaches, which are major representatives of data-driven approaches, have been widely and successfully applied to various traffic tasks. Significant progress has been made in following works. 😁  Deep belief network (DBN) [3]   Stacked auto-encoder (SAE) [4] However, it is difficult for these dense networks to extract spatial and temporal features from the input jointly. 😡To take full advantage of spatial features, some researchers use convolutional neural network (CNN) to capture adjacent relations among the traffic network, along with employing recurrent neural network (RNN) on time axis. 😁However, this approach has limitations as follow. 😡  The normal convolutional operation applied restricts the model to only process grid structures (e.g. images, videos) rather than general domains.    Rrecurrent networks for sequence learning require iterative training, which introduces error accumulation by steps.    RNN-based networks are widely known to be difficult to train and computationally heavy.1.3. Proposed ApproachFor overcoming the limitations of previous approaches, the author introduces several strategies to effectively model temporal dynamics and spatial dependencies of traffic flow. 😁  To fully utilize spatial information, the author models the traffic network by a general graph instead of treating it separately (e.g. grids or segments).    To handle the inherent deficiencies of recurrent networks, the author employs a fully convolutional structure on time axis.  Above all, the author proposes a novel deep learning architecture, the spatio-temporal graph convolutional networks (STGCN), for traffic forecasting tasks. 🤘 Q. IS THERE ANY DRAWBACK IN STGCN???  A. 2. PRELIMINARY2.1. Traffic Prediction on Road GraphsTraffic forecast as a typical time-series prediction problemPredicting the most likely traffic measurements (e.g. speed or traffic flow) in the next $H$ time steps given the previous $M$ traffic observations as,\\[\\hat{v}_{t+1}, ..., \\hat{v}_{t+H} = \\underset{v_{t+1}, ..., v_{t+H}}{\\mathrm{argmax}}\\log{P(v_{t+1}, ..., v_{t+H} | v_{t-M+1}, ..., v_{t})}\\tag{1}\\]where $v_t \\in \\mathbb{R}^{n}$ is an observation vector of $n$ road segments at time step $t$, each element of which records historical observation for a single road segment.Graph structured traffic time series problemIn this work, the author defines the traffic network on a graph and focuses on structured traffic time series. The traffic network is represented as an undirected graph (or directed one) $\\mathcal{G_t}$ with weights $w_{ij}$ as shown in Figure 1.   Figure 1. Graph-structured traffic data. [1]  At the $t$-th time step, in graph $\\mathcal{G}_t = (\\mathcal{V}_t, \\mathcal{E}, W)$,  $\\mathcal{V}_t$ is a finite set of vertices, corresponding to the observations from $n$ monitor stations at time $t$.    $\\mathcal{E}$ is a set of edges, indicating the connectedness between stations.    $W \\in \\mathbb{R}^{n \\times n}$ denotes the weighted adgacency matrix of $\\mathcal{G}_t$.   Q. DOES EDGES CAN HAVE ITS OWN TIME VARIANT VARIABLES???    (e.g. temperature of transmission lines in power system)  A. 2.2. Convolutions on GraphsIn this paper, the author introduces the notion of graph convolution operator “$*\\mathcal{G}$”  based on the conception of spectral filtering [7, 8].\\[\\begin{aligned} y &amp; = \\Theta *\\mathcal{G} x \\\\&amp; = \\Theta (L) x \\\\&amp; = \\Theta (U \\Lambda U^T) x \\\\&amp;= U \\Theta (\\Lambda) U^T x \\end{aligned}\\tag{2}\\]where  $x \\in \\mathbb{R}^{n}$ is a graph signal as an input (data from each vertex).    $y \\in \\mathbb{R}^{n}$ is filtered signal as an output.    $\\Theta(\\cdot)$ is a kernel (characteristic of the filter).    $U = [u_0, …, u_{n-1}] \\in \\mathbb{R}^{n\\times n}$, Graph Fourier basis, is the matrix of eigenvectors of the normalized graph Laplacian $L$.    $\\Lambda =diag([\\lambda_0, …, \\lambda_{n-1}]) \\in \\mathbb{R}^{n\\times n}$ is the matrix of eigenvalues of the normalized graph Laplacian $L$.  (check details of Laplacian matrix in appendix 7.1)As a result, a graph signal $x$ is filtered by a kernel $\\Theta$ can be defined with multiplication between $\\Theta$ and graph Fourier transform $U^T x$ [7].(check details of graph Fourier transform in appendix 7.2)In addition, due to its matrix multiplication, the computational complexity of graph convolution is $\\mathcal{O}(n^2)$. Q. WHY “NORMALIZED” L???  A. 3. PROPOSED MODEL3.1. Network ArchitectureThe author proposed a model architecture called spatio-temporal graph convolutional networks (STGCN). As shown in Figure 2, STGCN is composed of several spatio-temporal convolutional blocks.Each spatio-temporal convolutional blocks is formed as a “sandwich” structure with two gated sequential convolution layers and one spatial graph convolution layer in between.   Figure 2. Architecture of spatio-temporal graph convolutional networks (STGCN). [1]  3.2. Graphs CNNs for Extracting Spatial FeaturesThe traffic network generally organizes as a graph structure. Since 2-D convolutions on grids can only capture the spatial locality, attributes of traffic networks (graph structured data) were not fully extracted by 2-D convolution filters.Accordingly, in STGCN, the graph convolution is employed directly on graph-structured data to extract highly meaningful patterns and features in the space domain.However, there are two issues of the graph convolution expressed in Eq. (2). 😡  The kernel is not localized in space yet.    The computation of kernel $\\Theta$ in graph convolution by Eq. (2) can be expensive due to $\\mathcal{O}(n^2)$ multiplications with graph Fourier basis.  The authors applied two approximation strategies to overcome these issues. 😁Chebyshev Polynomials ApproximationChebyshev polynomial $T_k(x)$ is used to approximate kernels as a truncated expansion of order $K-1$ as follows.\\[\\begin{aligned}\\Theta (\\Lambda) &amp; = \\sum_{k=0}^{K-1} \\theta_k \\Lambda^k \\\\ &amp;\\approx \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{\\Lambda})\\end{aligned}\\]where  $\\tilde{\\Lambda} = 2 \\frac{\\Lambda}{\\lambda_{max}}-I_n$ ($\\lambda_{max}$ denotes the largest eigenvalues of $L$).    $\\theta \\in \\mathbb{R}^{n}$ is a vector of polynomial coefficient.  (check details of Chebyshev polynomials approximation in appendix 7.3)Using the Chebyshev polynomials approximation, the graph convolution can then be rewritten as,\\[\\begin{aligned} \\Theta*\\mathcal{G}x  &amp;= \\Theta(L)x \\\\ &amp;\\approx \\sum_{k=0}^{K-1} \\theta_k T_k(\\tilde{L})x \\end{aligned}\\tag{3}\\]where  $T_k(\\tilde{L})\\in\\mathbb{R}^{n\\times n}$ is the Chebyshev polynomial of order $k$    $\\tilde{L} \\in \\mathbb{R}^{n \\times n}$ the scaled Laplacian $\\tilde{L} = 2\\frac{L}{\\lambda_{max}} - I_n$.  As a result, we can localize the filter by restricting kernel $\\Theta$ to a polynomial of order $k$.Moreover, by recursively computing $K$ convolutions through the polynomial approximation, the cost of Eq. (2) can be reduced to $\\mathcal{O}(K|\\mathcal{E}|)$ as Eq. (3) shows [8].(check details of localizing convolution filters in appendix 7.4) Q. RESCALED??? WHY???  A. It makes eigenvalues in the range [-1, 1] to prepare for the recursive computation.  Q. WHY |E| IN COMPUTAIONAL COMPLEXITY???  A. 1st-order ApproximationA layer-wise linear formulation can be defined by stacking multiple localized graph convolutional layers with the first-order approximation of graph Laplacian [9].Due to the scaling and normalization in neural networks, we can further assume that $\\lambda_{max} \\approx 2$. Q. THE SCALING AND NORMALIZATION IN NEURAL NETS???  A. Thus, the Eq. (3) can be simplified to,\\[\\begin{aligned} \\Theta*\\mathcal{G}x &amp; \\approx \\theta_0x + \\theta_1(\\frac{2}{\\lambda_{max}}L-I_n)x \\\\ &amp;\\approx \\theta_0x - \\theta_1(D^{-1/2}WD^{-1/2})x \\end{aligned}\\tag{4}\\]where $\\theta_0$, $\\theta_1$ are two shared parameters of the kernel.In order to constrain parameters and stabilize numerical performances, $\\theta_0$ and $\\theta_1$ are replaced by a single parameter $\\theta$ by letting $\\theta = \\theta_0 = -\\theta_1$.Then, the graph convolution can be alternatively expressed as,\\[\\begin{aligned} \\Theta*\\mathcal{G}x &amp;= \\theta(I_n + D^{-1/2}WD^{-1/2})x \\\\&amp;= \\theta(\\tilde{D}^{-1/2}\\tilde{W}\\tilde{D}^{-1/2})x \\end{aligned} \\tag{5}\\]where  $W$ is renormalized by $\\tilde{W} = W + I_n$    $D$ is renormalized by $\\tilde{D_{ii}} = \\sum_j{\\tilde{W}_{ij}}$.  The authors stack the 1st-order approximation $K$ layers vertically. In this scenario, $K$ is the number of successive filtering operations, and the stack achieves the similar effect as $K$-localized convolutions do horizontally.Additionally, the layer-wise linear structure is parameter-economic and highly efficient for large-scale graphs, since the order of the approximation is limited to one.(check details of localizing convolution filters in appendix 7.4)Generalization of Graph ConvolutionsThe graph convolution operator “$*\\mathcal{G}$” defined on $x \\in \\mathbb{R}^n$ can be extended to multi-dimensional tensors.For a signal $C_i$ channels $X \\in \\mathbb{R}^{n \\times C_i}$, the graph convolution can be generalized by,\\[y_i = \\sum_{i=1}^{C_i} \\Theta_{ij}(L)x_i \\in \\mathbb{R}^n, 1 \\leq j \\leq C_o \\tag{6}\\]with the $C_i \\times C_o$ vectors of Chebyshev coefficients $\\Theta_{ij} \\in \\mathbb{R}^K$ ($C_i$, $C_o$ are the size of input and output of the feature maps, respectively).The graph convolution for 2-D variables is denoted as “$\\Theta *\\mathcal{G}X$” with $\\Theta \\in \\mathbb{R}^{K \\times C_i \\times C_o}$.3.3. Gated CNNs for Extracting Temporal FeaturesRNNs for traffic prediction still suffer from following. 😡  time-consuming iterations    complex gate mechanisms    slow response to dynamic changes.  On the contrary, CNNs have the superiority as follows. 😁  fast training    simple structures    no dependency constraints to previous steps.  The authors employ entire convolutional structures on time axis to capture temporal dynamic behaviors of traffic flows.This specific design allows parallel and controllable training procedures through multi-layer convolutional structures formed as hierarchical representations.   Figure 3. Temporal Gated-Conv Block. [1]  For each node in graph $\\mathcal{G}$, the temporal convolution explores $K_t$ neighbors of input elements without padding which leading to shorten the length of sequences by $K_{t}-1$ each time. Thus, input of temporal convolution for each node can be regarded as a length-$M$ sequence with $C_i$ channels as $Y \\in \\mathbb{R}^{M \\times C_i}$.The convolution kernel $\\Gamma \\in \\mathbb{R}^{K_t \\times C_i \\times 2C_o}$ is designed to map the input $Y$ to a single output element $[P : Q] \\in \\mathbb{R}^{(M-K_t+1) \\times (2C_o)}$ ($P, Q$ is split in half with the same size of channels).As a result, the temporal gated convolution can be defined as,\\[\\Gamma * \\tau Y=P \\odot \\sigma (Q) \\in \\mathbb{R}^{(M-K_t+1) \\times C_o} \\tag{7}\\]where  $P, Q$ are input of gates in GLU respectively    $\\odot$ denotes the element-wise Hadamard product.    $\\sigma$ is sigmoid gate controls which input $P$ of the current states are relevant for discovering compositional structure and dynamic variances in time series.     Figure 4. Structure of Gated Linear Unit (GLU). [12]   Q. WHY GLU, NOT ReLU OR SOMETHING ELSE???  A. The non-linearity gates contribute to the exploiting of the full input filed through stacked temporal layers as well. Furthermore, residual connections are implemented among stacked temporal convolutional layers. Similarly, the temporal convolution can also be generalized to 3-D variables by employing the same convolution kernel $\\Gamma$ to every node $\\mathcal{Y}_i \\in \\mathbb{R}^{M \\times C_i}$ (e.g. sensor stations) in $\\mathcal{G}$ equally, noted as “$\\Gamma * \\tau \\mathcal{Y}$” with $\\mathcal{Y} \\in \\mathbb{R}^{M \\times n \\times C_i}$.3.4. Spatio-Temporal Convolutional BlockIn order to fuse features from both spatial and temporal domains, the spatio-temporal convolutional block (ST-Conv block) is constructed to jointly process graph-structured time series.   Figure 5. Spatio-Temporal Convolutional (ST-Conv) Block. [1]  As illustrated in Figure 5, the spatial layer in the middle is to bridge two temporal layers which can achieve fast spatial-state propagation from graph convolution through temporal convolutions.The “sandwich” structure also helps the network sufficiently apply bottleneck strategy to achieve scale compression and feature squeezing by downscaling and upscaling of channels $C$ through the graph convolutional layer. Q. WHY IT HAS SANDWICH STRUCTURE???  A. Moreover, layer normalization is utilized within every ST-Conv block to prevent overfitting.The input and output of ST-Conv blocks are all 3-D tensors. For the input $v^l \\in \\mathbb{R}^{M \\times n \\times C^l}$ of block $l$, the output $v^{l+1} \\in \\mathbb{R}^{(M-2(K_t-1)) \\times n \\times C^{l+1}}$is computed by,\\[v^{l+1} = \\Gamma_1^l * \\tau ReLU(\\Theta^l * \\mathcal{G}(\\Gamma_0^l * \\tau v^l)) \\tag{8}\\]where  $\\Gamma_0^l$, $\\Gamma_1^l$ are the upper and lower temporal kernel within block $l$, respectively.    $\\Theta^l$ is the spectral kernel of graph convolution    $ReLU(\\cdot)$ denotes the rectified linear units function.     Figure 6. The framework STGCN consists of two ST-Conv blocks and a fully-connected output layer in the end. [1]  3.5. Loss FunctionWe use L2 loss to measure the performance of our model.\\[L(\\hat{v};W_{\\theta})=\\sum_{t}\\| \\hat{v}(v_{t-M+1}, ..., v_t, W_\\theta) - v_{t+1} \\|^2 \\tag{9}\\]where  $W_\\theta$ are all trainable parameters in the model    $v_{t+1}$ is the ground truth    $\\hat{v}(\\cdot)$ denotes the model’s prediction  3.6. Recap of the Main Characteristics STGCN  STGCN is a universal framework to process structured time series.    It is not only able to tackle traffic network modeling and prediction issues but also to be applied to more general spatio-temporal sequence learning tasks.    The spatio-temporal block combines graph convolutions and gated temporal convolutions, which can extract the most useful spatial features and capture the most essential temporal features coherently.    The model is entirely composed of convolutional structures and therefore achieves parallelization over input with fewer parameters and faster training speed.  4. EXPERIMENTS &amp; RESULTS4.1. Dataset DescriptionBJER4 was gathered from the major areas of east ring No.4 routes in Beijing City by double-loop detectors.  The traffic data are aggregated every 5 minutes.    There are 12 roads selected for the experiment.  PeMSD7 was collected from Caltrans Performance Measurement System (PeMS) in real-time by over 39,000 sensor stations, deployed across the major metropolitan areas of California state highway system.  The traffic data are aggregated every 5 minutes.    The authors randomly select a medium and a large scale among the District 7 of California containing 228 and 1,026 stations, labeled as PeMSD7(M) and PeMSD7(L), respectively, as data sources (shown in the left of Figure 7).     Figure 7. PeMS sensor network in District 7 of California (left), each dot denotes a sensor station; Heat map of weighted adjacency matrix in PeMSD7(M) (right). [1]  4.2. Data Preprocessing  Interpolation method: Linear interpolation    Normalization method: Z-score  \\[\\begin{aligned}Z &amp;= \\frac{x-\\mu}{\\sigma}, \\\\ &amp; \\text{where } \\mu \\text{ is mean and } \\sigma \\text{ is standard deviation}.\\end{aligned}\\]4.3. Experimental SettingsAll the tests use 60 minutes as the historical time window.\\[\\hat{v}_{t+1}, ..., \\hat{v}_{t+H} = \\underset{v_{t+1}, ..., v_{t+H}}{\\mathrm{argmax}}\\log{P(v_{t+1}, ..., v_{t+H} | v_{t-M+1}, ..., v_{t})}\\tag{1}\\]With Eq. (1) and the time window setting, 12 observed data points ($M = 12$) are used to forecast traffic conditions in the next 15, 30, and 45 minutes ($H = 3, 6, 9$).Evaluation MetricTo measure and evaluate the performance of different methods, three following metrics are adopted.  Mean Absolute Errors (MAE)\\[\\frac{1}{n}\\sum_{1}^{n}{\\| y_i - \\hat{y_i} \\|}\\]  Mean Absolute Percentage Errors (MAPE)\\[\\frac{100}{n}\\sum_{1}^{n}{ \\frac{y_i - \\hat{y_i}}{y_i} }\\]  Root Mean Squared Errors (RMSE)\\[\\frac{1}{n}\\sum_{1}^{n}{\\sqrt{(y_i - \\hat{y_i})^2}}\\] Q. WHY DO WE NEED MULTIPLE METRICS???  A. BaselinesThe authors set up two types of models based on STGCN framework.  STGCN(Cheb) with the Chebyshev polynomials approximation    STGCN(1st) with the 1st-order approximation ($K=1$).  STGCN based models are compared with following baselines.  Historical Average (HA)    Linear Support Vector Regression (LSVR)    Auto-Regressive Integrated Moving Average (ARIMA)    Feed-Forward Neural Network (FNN)    Full-Connected LSTM (FC-LSTM)    Graph Convolutional GRU (GCGRU)  4.4. Experimental ResultsBenefits of Spatial TopologyThrough effectively utlizing spatial structure of the given data, the STGCN based models have achieved a significant improvement on short and mid-and-long term forecasting.   Table 1. Performance comparison of different approaches on the dataset BJER4. [1]     Table 2. Performance comparison of different approaches on the dataset PeMSD7. [1]     Figure 8. Speed prediction in the morning peak and evening rush hours of the dataset PeMSD7. [1]  Training Efficiency and GeneralizationTo see the benefits of the convolution along time axis in our proposal, we summarize the comparison of training time between STGCN and GCGRU in Table 3.   Table 3. Time consumptions of training on the dataset PeMSD7. [1]  In order to further investigate the performance of compared deep learning models, the authors plot the RMSE and MAE of the test set of PeMSD7(M) during the training process, see Figure 9.Those figures also suggest that the models can achieve muchfaster training procedure and easier convergences. Thanks to the special designs in ST-Conv blocks, the models have superior performances in balancing time consumption and parameter settings. Q. HOW IT ACHIEVES SUPERIOR PERFORMANCE IN BALANCING TIME COMSUMPTION &amp; PARAMETER SETTING???  A.    Figure 9. Test RMSE versus the training time (left); Test MAE ver- sus the number of training epochs (right). (PeMSD7(M)) [1]  Moreover, the number of parameters in STGCN ($4.54 \\times 10^5$) only accounts for around two third of GCGRU, and saving over 95% parameters compared to FC-LSTM.5. CONCLUSIONIn this paper, the authors propose  A novel deep learning framework STGCN for traffic prediction.    Integrating graph convolution and gated temporal convolution through spatio-temporal convolutional blocks.  The experiments shows  Benefits of spatial topology            The model outperforms other state-of-the-art methods on two real-world datasets.        The results indicate its great potentials on exploring spatio-temporal structures from the input.          Training efficiency and generalization            Faster training (parallelization).        Fewer parameters with flexibility and scalability.         Q. WHY/HOW IT ACHEIVES FELXIBILITY AND SCALABILITY???  A. These features are quite promising and practical for scholarly development and large-scale industry deployment. In the future, we will further optimize the network structure and parameter settings.Moreover, the proposed framework can be applied into more general spatio-temporal structured sequence forecasting scenarios, such as evolving of social networks, and preference prediction in recommendation systems, etc.6. MY RESEARCH PROJECTPurpose / Goal  Forecast or detect (in real-time) cascading outages in power systems.Approach  Use a GNN based model to predict or detect cascading outages.ExperimentsStep 1. Data Generation  Need to introduce randomness to create large size of dataset.        Randomness will be given by the method that generated the uncertain loads in [16]:  \\[d := d + \\mathcal{N}(\\mu=0, \\sigma = 0.03 * d)\\]          $d$ is a load.        $\\mathcal{N}$ is normal distribution with mean zero and standard deviation proportional to the load.         Q. WHICH FEATURES (e.g. $P_d, Q_d, P_g, Q_g$ or outage event time $t_{event}$) SHOULD BE GIVEN RANDOMNESS?  A.   Codes            Generate N-2 Contingency Datasets.py        Generate Datasets.ipynb        Exploratory Data Analysis.ipynb        Step 2. Design the GNN Model Architecture  The model should able to utilze spatial and temporal feature of the data.            graph structured data: spatial feature        time series data: temporal feature          Models based on STGCN architecture [1] can extract and learn the both features (spatial &amp; temporal) from the data.    Codes            yet not ready…😭        Step 3. Train &amp; Test the Model  🤔Step 4. Tune the Hyper-parameters  🤔Results (What we want to see…)  High enough prediction (or detection) accuracy.    Extremely high computational efficiency compared to old methods.    A GNN based model having significantly fewer nodes (trainable parameters) than other deep learning models.  7. APPENDIX7.1. Laplacian &amp; Symmetric normalized Laplacian [10]LaplacianGiven a simple graph $\\mathcal{G}$ with $n$ vertices, its Laplacian matrix $L_{n \\times n}$ is defined as,\\[L = D - A\\]where  $D$ is the degree matrix of the graph.    $A$ is adjacency matrix.  The elements of $L$ are given by\\[L_{ij}:= \\begin{cases} deg(v_i) &amp;\\text{if } i=j \\\\ -1 &amp;\\text{if } i\\neq j \\text{ and } v_i \\text{ is adjacent to } v_j \\\\ 0 &amp;\\text{otherwise} \\end{cases}\\]where  $deg(v_i)$ is the degree of the vertex $i$.Symmetric normalized LaplacianThe symmetric normalized Laplacian matrix is defined as,\\[L = I - D^{-1/2} A D^{-1/2}\\]The elements of $L^{sym}$ are given by\\[L_{ij}:=\\begin{cases}1 &amp;\\text{if } i=j \\text{ and } deg(v_i) \\neq 0\\\\-\\frac{1}{\\sqrt{deg(v_i)deg(v_j)}} &amp;\\text{if } i\\neq j \\text{ and } v_i \\text{ is adjacent to } v_j \\\\0 &amp;\\text{otherwise}\\end{cases}\\]   Figure 10. Example of a General Graph and its Degree, Adjacency, and Laplacian Matrix. [10]  7.2. Graph Fourier transformGraph Fourier transform is a mathematical transform which eigendecomposes the Laplacian matrix of a graph into eigenvalues and eigenvectors. Analogously to classical Fourier Transform, the eigenvalues represent frequencies and eigenvectors form what is known as a graph Fourier basis [11].Lets assume we have a graph $\\mathcal{G}_t = (\\mathcal{V}, \\mathcal{E}, W)$, where $\\mathcal{V}$ is a finite set of $|\\mathcal{V}|=n$ verices, $\\mathcal{E}$ is a set of edges, and $W \\in \\mathbb{R}^{n\\times n}$ is a weighted adjacency matrix.The definition of Laplacian matrix is\\[L = I_n - D^{-\\frac{1}{2}} W D^{-\\frac{1}{2}} = U \\Lambda U^T \\in \\mathbb{R}^{n\\times n}\\]where  $I_n$ is an identity matrix.    $D \\in \\mathbb{R}^{n\\times n}$ is the diagonal degree matrix with $D_{ii} = \\sum_{j}{W_{ij}}$.    $U = [u_0, …, u_{n-1}] \\in \\mathbb{R}^{n\\times n}$ is a Graph Fourier basis.    $\\Lambda =diag([\\lambda_0, …, \\lambda_{n-1}]) \\in \\mathbb{R}^{n\\times n}$ is the diagonal matrix of eigenvalues of $L$.  The graph Fourier transform of a signal $x \\in \\mathbb{R}^{n}$ is then deinfed as as $\\hat{x} = U^{T}x \\in \\mathbb{R}^{n}$, and its inverse as $x=U\\hat{x}$ [13].  7.3. Chebyshev Polynomial &amp; Approximation [14, 15]The Chebyshev polynomials are two sequences of polynomials related to the sine and cosine functions, notated as $T_n(x)$ and $U_n(x)$.\\[T_n(cos(\\theta))=cos(n\\theta)\\]\\[U_n(cos(\\theta))sin(\\theta)=sin((n+1)\\theta)\\]The Chebyshev polynomials of the first kind are obtained from the recurrence relation as follows.\\[T_0(x)=1 \\\\T_1(x)=x \\\\T_{n+1}(x)=2xT_n(x)-T_{n-1}(x)\\]   Figure 11. Plot of the first five Tn Chebyshev polynomials of the first kind. [14]  One can obtain polynomials very close to the optimal one by expanding the given function in terms of Chebyshev polynomials and then cutting off the expansion at the desired degree.\\[f(x) \\approx \\sum_{i=0}^{\\infty}{c_i T_{i}(x)}\\]This is similar to the Fourier analysis of the function, using the Chebyshev polynomials instead of the usual trigonometric functions.7.4. Localizing Convolutional Filter in SpaceThe Eq. (2) represents spectral filtering of graph signal.\\[\\begin{aligned} y &amp; = \\Theta *\\mathcal{G} x \\\\&amp; = \\Theta (L) x \\\\&amp; = \\Theta (U \\Lambda U^T) x \\\\&amp;= U \\Theta (\\Lambda) U^T x \\end{aligned}\\tag{2}\\]The filter is characterized by its kernel ($\\Theta(\\cdot)$), and the simplest kernerl we can imagine is a non-parametic filter, i.e. the kernel parameters $\\theta_k \\in \\mathbb{R}$  $(k=1, …, n)$ are all free.\\[\\Theta(\\Lambda) = diag(\\theta)\\]In this case, the filter has a limitaion that it is not localized in space. 😡However, this issue can be solved by following two strategies. 😁A. Restricting kernel to polynomial by Chebyshev approximation (Horizontal ver.)We can localize the filter in space by restricting the kernel to a polynomial [8]. As a result, the convolutional filter is restricted as a polynomial filter. Moreover, by using Chebyshev approximation, we could limit the radius of the convolutional operation.The localized filter can be expressed as follows.\\[\\begin{aligned}\\Theta(\\Lambda) &amp;= \\sum_{k=0}^{K-1}{\\theta_k \\Lambda^{k}} \\\\ &amp;\\approx \\sum_{k=0}^{K-1}{\\theta_k T_{k}(\\tilde{\\Lambda})}\\end{aligned}\\]where  $\\tilde{\\Lambda} = 2 \\frac{\\Lambda}{\\lambda_{max}}-I_n$ ($\\lambda_{max}$ denotes the largest eigenvalues of $L$).    $\\theta \\in \\mathbb{R}^{n}$ is a vector of polynomial coefficient.    $K$ is a radius of the convolutional filter.  B. Applying a stack of 1st-order approximated kernel (Vertical ver.)By 1st-order approximation, we can get a simplified filter as follows.\\[\\Theta(\\Lambda) \\approx \\theta_0 + \\theta_1(\\frac{2}{\\lambda_{max}}\\Lambda-I_n)\\]where $\\theta_0$, $\\theta_1$ are two shared parameters of the kernel.Applying a stack of graph convolutions with the 1st-order approximation vertically that achieves the similar effect as $K$-localized convolutions do horizontally, all of which exploit the information from the $(K-1)$-order neighborhood of central nodes [1].Reference[1] B. Yu, H. Yin, and Z. Zhu, “Spatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting,” arXiv.org, 12-Jul-2018.[2] B. Tefft, S. Rosenbloom, R. Santos, and T. Triplett, “American Driving Survey: 2014 – 2015,” AAA Foundation, 14-Jun-2018. [Online]. Available: https://aaafoundation.org/american-driving-survey-2014-2015/. [Accessed: 15-Feb-2021].[3] Yuhan Jia, Jianping Wu, and Yiman Du, “Traffic speed prediction using deep learning method,” 2016 IEEE 19th International Conference on Intelligent Transportation Systems (ITSC), 2016.[4] Y. Lv, Y. Duan, W. Kang, Z. Li and F. Wang, “Traffic Flow Prediction With Big Data: A Deep Learning Approach,” in IEEE Transactions on Intelligent Transportation Systems, vol. 16, no. 2, pp. 865-873, April 2015, doi: 10.1109/TITS.2014.2345663.[5] M. Niepert, M. Ahmed, and K. Kutzkov, “Learning Convolutional Neural Networks for Graphs,” arXiv.org, 08-Jun-2016. [Online]. Available: https://arxiv.org/abs/1605.05273. [Accessed: 05-Apr-2021].[6] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, “Spectral Networks and Locally Connected Networks on Graphs,” arXiv.org, 21-May-2014. [Online]. Available: https://arxiv.org/abs/1312.6203. [Accessed: 05-Apr-2021].[7] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst, “The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains,” IEEE Signal Processing Magazine, vol. 30, no. 3, pp. 83–98, 2013.[8] M. Defferrard, X. Bresson, and P. Vandergheynst, “Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering,” arXiv.org, 05-Feb-2017. [Online]. Available: https://arxiv.org/abs/1606.09375. [Accessed: 05-Apr-2021].[9] T. N. Kipf and M. Welling, “Semi-Supervised Classification with Graph Convolutional Networks,” arXiv.org, 22-Feb-2017. [Online]. Available: https://arxiv.org/abs/1609.02907v4. [Accessed: 05-Apr-2021].[10] “Laplacian matrix,” Wikipedia, 10-Jan-2021. [Online]. Available: https://en.wikipedia.org/wiki/Laplacian_matrix. [Accessed: 03-Feb-2021].[11] “Graph Fourier Transform,” Wikipedia, 30-Dec-2020. [Online]. Available: https://en.wikipedia.org/wiki/Graph_Fourier_Transform. [Accessed: 01-Mar-2021].[12] M. Elbayad, “Rethinking the Design of Sequence-to-Sequence Models for Efficient Machine Translation,” TEL, 03-Nov-2020. [Online]. Available: https://tel.archives-ouvertes.fr/tel-02986998. [Accessed: 09-Apr-2021].[13] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst, “The emerging field of signal processing on graphs: Extending high-dimensional data analysis to networks and other irregular domains,” IEEE Signal Processing Magazine, vol. 30, no. 3, pp. 83–98, 2013.[14] “Chebyshev polynomials,” Wikipedia, 08-Apr-2021. [Online]. Available: https://en.wikipedia.org/wiki/Chebyshev_polynomials. [Accessed: 14-Apr-2021].[15] “Approximation theory,” 11-Jan-2021. [Online]. Available: https://en.wikipedia.org/wiki/Approximation_theory. [Accessed: 14-Apr-2021].[16] D. Deka and S. Misra, “Learning for DC-OPF: Classifying active sets using neural nets,” 2019 IEEE Milan PowerTech, Milan, Italy, 2019, pp. 1-6.",
        "url": "//research/ml&amp;dl/2021/04/14/STGCN.html"
      }
      ,
    
      "research-mathematics-2021-01-14-householder-html": {
        "title": "Householder QR Factorization",
        "tags": "Math, Linear Algebra, Mathematics, ALAFF",
        "date": "January 14, 2021",
        "author": "",
        "category": "",
        "content": "This article was written by referring to the Fall 2020 Numerical Analysis: Linear Algebra Course and the following links.  ALAFF: Gram-Schmidt Orthogonalization  ALAFF Git RepositoryUnitary Matrix   Figure 1.  Householder transformation   Figure 2.     Code 1. Householder transformation in python.Householder QR factorization algorithm   Figure 3.     Figure 4.     Code 2. Householder QR factorization in python.   Code 3. Householder LQ factorization in python.Forming Q   Figure 5.     Figure 6.     Code 4. Form Q from Householder QR factorization in python.Applying QHOrthogonality of resulting Q  test_orthogonality.ipynbBlocked Householder QR factorization   Figure 7.  References[1]",
        "url": "//research/mathematics/2021/01/14/Householder.html"
      }
      ,
    
      "research-cs-2021-01-10-pep8-html": {
        "title": "(Python-Dev Tips) PEP8",
        "tags": "CS, Dev, Python",
        "date": "January 10, 2021",
        "author": "",
        "category": "",
        "content": "  Git Basic  Virtual Environment  PEP8  JupyterThis article covers what is PEP 8 and how to follow this convention with minimal effort and no difficult. This posting referred to the following articles.  PEP 8 – Style Guide for Python Code  How to Write Beautiful Python Code With PEP 8  How to Auto-Format Your Python Code with BlackWhat is PEP 8Why we need PEP 8  Guidelines for writing Python.  Good Readability  Revisiting old project  Easy to spot bugs  CollaborationAuto-formatter   \"Any Questions?\"  Reference",
        "url": "//research/cs/2021/01/10/pep8.html"
      }
      ,
    
      "research-energy-2021-01-05-cascading-outage-sim-dynamic-html": {
        "title": "(Research Proj) Cascading Outage Simulator - Dynamic",
        "tags": "Energy, Power, Cascading Outage, Dynamic, DAE, Research Proj, Paper review",
        "date": "January 5, 2021",
        "author": "",
        "category": "",
        "content": "This article is about a review of the paper [1], and is the first part of a personal research project to apply Graph Neural Network (GNN) to the field of cascading outage prediction or detection.The primary purpose is to create large-scale datasets for training GNN-based models through the cascading outage simulator presented in this paper.  Research Project’s Git Repository1. CASCADING OUTAGE SIMULATORWHAT &amp; WHYThe importance of studying cascading outages has been recognized [2]-[4]. However, since electrical power networks are very large and complex systems [5], understanding the many mechanisms by which cascading outages propagate is challenging [1].Cascading outage simulators are designed to set and reproduce scenarios that can occur in the electric grid, and it allow us to study a wide variety of different mechanisms of cascading outages.IN THE PAPERThe paper presents the design of and results from a new non-linear dynamic model of cascading failure in power system,  called “Cascading Outage Simulator with Multi-process Integration Capabilities” (COSMIC).In COSMIC [1], …  Dynamic components are modeled using differential equations.    Power flows are represented using non-linear power flow equations.    Discrete changes (e.g., components failures, load shedding) are described by a set of equations (constraints).  COSMIC has the following benefits [1].  It provids an open platform for research and development.    The dynamic/adaptive time step and recursive islanded time horizons implemented in this simulator which allows for faster computations during, near, steady-state regimes, and fine resolution during transient phases.    It can be easily integrated with High Performance Computing (HPC) clusters to run many simulations simultaneously at a much lower cost.  2. HYBRID SYSTEM MODELING IN COSMICA. Hybrid differential-algebraic formulationDynamic power networks are modeled as sets of DAEs. Each DAE is composed of three parts:  i. A set of Differential equations  ii. A set of Algebraic equations  iii. A set of Constraintsi. A set of Differential equations\\[\\frac{d\\mathbf{x}}{dt}=\\mathbf{f}(t, \\mathbf{x}(t), \\mathbf{y}(t), \\mathbf{z}(t)) \\tag{1}\\]  $\\mathbf{x}$ is a vector of continuous state variables that change with time according to a set of differential equations.    (1) represent the machine dynamics (APPENDIX - A).  ii. A set of Algebraic equations\\[\\mathbf{g}(t, \\mathbf{x}(t), \\mathbf{y}(t), \\mathbf{z}(t)) =0 \\tag{2}\\]  $\\mathbf{y}$ is a vector of continuous state variables that have pure algebraic relationships to other variables in the system.    (2) encapsulate the standard ac power flow equations (APPENDIX - B).    (2) is largely dependent on the load models (Figure 1. ZIPE models).  Q. WHAT IS EXPONENTIAL MODEL???   Figure 1. Illustrates a dramatic impact of load models on algebraic convergence. [1]  iii. A set of Constarints\\[\\mathbf{h}(t, \\mathbf{x}(t), \\mathbf{y}(t), \\mathbf{z}(t))&lt;0 \\tag{3}\\]  $\\mathbf{z}$ is a vector of state variables (relay status) that can only take integer states $( z_i ∈ [0, 1])$.    (3) represent the constraints.    If a constraint $\\mathbf{h_i}(…)&lt;0$ fails (outage occurs), an associated counter function $\\mathbf{d_i}$ (relay) activates.  cf. What happens during cascading failures?During cascading failures, power systems many undergo discrete changes. The discrete event(s) will consequently change the systems dynamic response and algebraic equations, which may result in cascading failures, system islanding, and large blackouts.B. Relay modelingMajor disturbances cause system oscillations, and these oscillations may naturally die out as the system adjusts to a new equilibrium. In order to ensure that relays do not trip due to brief transient state changes, time-delays are added to each protective relay in COSMIC.Five types of protective relays are modeled in COSMIC:  Over-current (OC) relays    Distance (DIST) relays    Temperature (TEMP) relays    Under-voltage load shedding (UVLS) relays    Under-frequency load shedding (UFLS)  C. Solving the hybrid DAECOSMIC used the following two strategies to solve the hybrid DAE.  COSMIC uses the trapezoidal rule to simultaneously integrate and solve the differential and algebraic equations.    COSMIC implements a variable time-step size in order to trade-off between the diverse time-scales of the dynamics.            During transition periods: small step size → fine resolution.        During steady-state periods: large step size → faster computation.        Trapezoidal Rule   Figure 2. Trapezoidal Rule [6]  \\[\\int_{a}^{b} f(x) \\,dx = \\frac{\\Delta x}{2}[f(x_0) + 2f(x_1) +... + 2f(x_{n-1}) + f(x_n)]\\]DAE during discrete event\\[0 = \\mathbf{x} + \\frac{t_d-t}{2} [\\mathbf{f}(t)+\\mathbf{f}(t_d, \\mathbf{x}_d, \\mathbf{y}_d, \\mathbf{z}_d)] \\tag{4}\\] Q. HOW TO APPLY TRAPEZOIDAL RULE TO A DISCRETE POINT??? \\[0=\\mathbf{g}(t_d, \\mathbf{x}_+, \\mathbf{y}_+, \\mathbf{z}) \\tag{5}\\]\\[0&gt;\\mathbf{h}(t_d, \\mathbf{x}_+, \\mathbf{y}_+) \\tag{6}\\]\\[0=\\mathbf{d}(t_d, \\mathbf{x}_+, \\mathbf{y}_+) \\tag{7}\\]where  $t$ is the previous time point.    $t_d$ is the point a discrete event occurs.  Because of the adaptive time step size, COSMIC retains $t_d$ from $t_d = t + \\Delta t_d$, in which $\\Delta t_d$ is found by linear interpolation of two time steps. Q. HOW THE LINEAR INTERPOLATION WORKS IN HERE??? Time-Domain Simulation AlgorithmThe description of Time-Domain Simulation Algorithm implemented in COSMIC and a corresponding flowchart are as follows.The feature of this algorithm that we need to focus is that when network separation occurs, each subnetwork is computed independently in a recursive manner.   Figure 3. Time-Domain Simulation Algorithm [1]     Figure 4. Flowchart of Time-Domain Simulation Algorithm  3. EXPERIMENTS AND RESULTSIn this paper, the performance and characteristics of COSMIC were explored through several experiments as follows.A. Polar formulation vs. Rectangular formulation in computational efficiencyPurpose  To compare the computational efficiency of the polar and rectangular formulations of the model. Q. WHY DO WE NEED TO COMPARE THE PERFOMANCE BETWEEN RECT AND POLAR??? Used test systems  39-bus system    2383-bus system  Results  On Table I, in 39-bus case, the rectangular formulation required fewer linear solves for different demand losses.    On Table II, in 2383-bus case, there was no significant improvement for the rectangular formulation over the polar formulation, and the number of linear solves that resulted from both forms were almost identical.     Table I &amp; Table II. Performance comparison between Rect &amp; Polar [1]   Q. WHY DO WE NEED TO KNOW ABOUT THE DENSITY OF THE JACOBIAN MATRICES??? B. Relay event illustrationPurpose  To illustrate the different relay functions implemented in COSMIC and their time delay algorithms.Used test systems  9-bus systemResults   Figure 5. Bus voltage magnitudes when the branch from bus 6 to bus 9 in the 9-bus system is tripped. [1]    A single-line outage was occurred at $t=10$ seconds, and  DIST relay timer activate.    $t_{preset-delay}=0.5$    $P_1 (t=10.5)$: $t_{delay}$ ran out, and another line outage was occurred.    $P_2$: the magenta voltage trace violated the limit, and UVLS relay timer activate.    $P_3$: UVLS relay took action and shed 25% of the initial load at the bus.  C. Cascading outage examplesPurpose  To demonstrates how COSMIC processes cascading events such as line branch outages, load shedding, and is-landing.Used test systems  39-bus system    2383-bus system  Results39-Bus Case   Table III. 39-Bus Case Cascading Outage Example [1]    At  $t=3.00$ sec, the system suffered a strong dynamic oscillation after the initial two exogenous events (branches 2–25 and 5–6).    At  $t=54.06$ sec, the first OC relay at branch 4–5 triggered.    At  $t=55.06$ and $t=55.07$ sec, load shedding at two buses (Bus 7 and Bus 8) occurred.    At $t=55.28$ sec, another two branches (10–13 and 13–14) shut down after OC relay trips. These events separated the system into two islands.    At $t=55.78$ sec, two branches (3–4 and 17–18) were taken off the grid and this resulted in another island. The system eventually ended up with three isolated networks.  2383-Bus Case   Figure 6. 2383-Bus Case Cascading Outage Example [1]    Number 0 with black highlights denotes the two initial events (N-2 contingency).    Other sequential numbers indicate the rest of the branch outages.    In this example, 24 branches are off-line and cause a small island (within the dashed circle) in the end.    The dots with additional red squares indicate buses where load shedding happens.     Figure 7. Branch outage events &amp; Load-shedding events listed in Figure 8 [1]  The top panel in Figure 7 shows the timeline of all branch outage events for the 2383-bus cascading scenario, and the lower panel zooms in the load-shedding events.What we found here are …  In the early phase of this cascading outages, the occurrence of the components failed relatively slowly, but it speeds up as the number of failures increased (check top panel).    When the system condition was substantially compromised, fast collapse occurs and the majority of the branch undergo outages as well as the load shedding events (check lower panel).  D. N-2 contingency analysisPurpose  To studies the impact of different load modeling assumptions on cascading failure sizes.Used test systems  2383-bus systemResultsDemand LossFigure 10 shows the complementary cumulative distribution function (CCDF) of demand losses for these four groups of simulations.   Figure 8. CCDF Demand Loss [1]    The CCDF plots of demand losses exhibit a heavy-tailed blackout size distribution, which are typically found in both historical blackout data and cascading failure models [7]. Q. WHY A HEAVY-TAILED DIST IS EASILY FOUND IN HISTORICAL DATA AND CASCADING FAILURE MODELS???    Table IV. Average demand loss, average branch outages, and the probabilityies of loss for different load models [1]    The constant Z load model ($Z_{100}I_0P_0E_0$) shows the best performance based on the average power loss and the probability of large blackout (listed in Table IV).    As can be seen in Table IV, the probabilities of large demand losses varies from 2.5% to 3.5% for those four load configurations.    These results show that load models play an important role in dynamic simulation and may increase the frequency of nonconvergence if they are not properly modeled.   Q. WHAT IS THE EXACT MEANDING OF NOT PROPERLY MODELED??? E. Comparison with a dc cascading outage simulatorPurpose  To compare results from COSMIC with results from a dc-power flow based model of cascading failure.    It will help us to understand similarities and differences between these two different modeling approaches.  Used test systems  2383-bus systemResultsThe probabilities of demand losses   Figure 9. CCDF Demand Loss for COSMIC &amp; DC Simulator [1]    The probability of demand losses in the dc simulator is lower than that of COSMIC for the same amount of demand losses.    The dc model is much more stable and does not run into problems of numerical nonconvergence.    COSMIC assumes that the network or sub-network in which the numerical failure occurred experienced a complete blackout.    As a result, numerical failures in solving the DAE system greatly contributed to the larger blackout sizes. → It may deteriorate the accuracy.  DC model  Pros            It is numerically stable, making it possible to produce results that can be statistically similar to data from real power systems [8].          Cons            It includes numerous simplifications that are substantially different from the “real” system.        Dynamic model  Pros            It includes many mechanisms of cascading that cannot be represented in the dc model.          Cons            It needs many assumptions that are needed substantially impact the outcomes, potentially in ways that are not fully accurate.        Path Agreement Measurement [9]\\[R(m_1, m_2) = \\sum_{i=1}^{|C|}\\frac{1}{C} \\frac{|A_i \\cap B_i|}{|A_i \\cup B_i|} \\tag{8}\\]where  models $m_1$ and $m_2$ are both subjected to the same set of exogenous contingencies $C=${$c_1,c_2,…$}.    It measures the average agreement in the set of dependent events that result from each contingency in each model.     Table V. Statical Results for the Comparison between COSMIC &amp; DC Simulator [1]    Table V shows that the average between the two models for the whole set of sequences is 0.1948, which means that there are substantial differences between cascade paths in the two models.    Part of the reason is that the dc model tends to produce longer cascades and consequently increase the denominator in (8).   Q. WHY DC MODEL TENDS TO PRODEUCE LONGER SCENARIOS???   In order to control this, we computed only for the first ten branch outage events (early stage).    The average R increased to 0.3487, and some of the cascading paths showed a perfect match ($R=1$).    This suggests that the cascading paths resulting from the two models tend to agree during the early stages of cascading, when nonlinear dynamics are less pronounced, but disagree during later stages.  4. CONCLUSIONThrough the above experiments, the following conclusions are drawn.  COSMIC represents a power system as a set of hybrid discrete/continuous differential algebraic equations, simultaneously simulating protection systems and machine dynamics.    From the N−2 contingency analysis, we found that COSMIC produces heavy-tailed blackout size distributions, which are typically found in both historical blackout data and cascading failure models [7] (Figure 8).    From the N−2 contingency analysis, we found that the blackout size results show that load models can substantially impact cascade sizes (Table IV).    From the comparison with a dc cascading outage simulator, we found that the relative frequency of very large events may be exaggerated in dynamic model due to numerical non-convergence (about 3% of cases).    From the comparison with a dc cascading outage simulator, we found that the two models largely agreed for the initial periods of cascading (for about 10 events), then diverged for later stages where dynamic phenomena drive the sequence of events.    Detailed dynamic models of cascading failure can be useful in understanding the relative importance of various features of these models.  5. MY RESEASRCH PROJECTPurpose / Goal  Forecast or detect (in real-time) cascading outages in power systems.Approach  Use a GNN based model to predict or detect cascading outages.ExperimentsStep 1. Data Generation  Need to introduce randomness to create large size of dataset.        Randomness will be given by the method that generated the uncertain loads in [10]:  \\[d := d + \\mathcal{N}(\\mu=0, \\sigma = 0.03 * d)\\]          $d$ is a load.        $\\mathcal{N}$ is normal distribution with mean zero and standard deviation proportional to the load.         Q. WHICH FEATURES (e.g. $P_d, Q_d, P_g, Q_g$ or outage event time $t_{event}$) SHOULD BE GIVEN RANDOMNESS?   Codes            Generate N-2 Contingency Datasets.py        Generate Datasets.ipynb        Exploratory Data Analysis.ipynb        Step 2. Design the GNN Model Architecture  Does the model ARCHITECTURE is proper for the GOAL?    What is the STRENGTH of the model ARCHITECTURE? and WHY?  Step 3. Train &amp; Test the ModelStep 4. Tune the Hyper-parameters  🤔Results (What we want to see…)  High enough prediction or detection accuracy.    Extremely high computational efficiency compared to old methods.    A GNN based model having significantly fewer nodes (trainable parameters) than other deep learning models.  6. APPENDIXA. Differential equations in dynamic power system [1]Equation for rotor speed\\[M \\frac{dw_i}{dt} = P_{m,i} - P_{g,i} - D(w_i-1)\\]where  $\\forall i \\in N_G$ ($N_G$ is the set of all generator buses).    $M$ is a machine inertia constant.    $w_i$ is a rotor speed.    $P_{m,i}$ is the mechanical power input.    $P_{g,i}$ is the generator power output.    $D$ is a daping constant.  Equation for rotor angle\\[\\frac{d\\delta_i(t)}{dt} = 2 \\pi f_0 (w_i-1)\\]where  $delta_i(t)$ is the rotor angle.    $f_0$ is the nominal frequency.    $w_i$ is fortor speed.  etc.B. AC power flow equation [11]Relation between following three compenets.  real/reactive power injected into each bus ($P_i, Q_i; i=1, 2, …, n$)    bus voltage magnitude of each bus ($V_i; i=1, 2, …, n$)    phase angle of each bus ($\\theta_i; i=1, 2, …, n$).  \\[P_i = V_i\\sum_{k=1}^{n}\\{ G_{ik} cos(\\theta_i-\\theta_k) +B_{ik}sin(\\theta_i-\\theta_k) \\}\\]\\[Q_i = V_i\\sum_{k=1}^{n}\\{ G_{ik} sin(\\theta_i-\\theta_k) +B_{ik}cos(\\theta_i-\\theta_k) \\}\\]where  $n$ is the number of buses of the system.    $Y_{ik} = G_{ik} + j B_{ik}$ is (i, k)-th entry of Y-bus matrix.  REFERENCES[1] J. Song, E. Cotilla-Sanchez, G. Ghanavati and P. D. H. Hines, “Dynamic Modeling of Cascading Failure in Power Systems,” in IEEE Transactions on Power Systems, vol. 31, no. 3, pp. 2085-2095, May 2016.[2] M. Papic et al., “Survey of tools for risk assessment of cascading outages,” in Proc. IEEE Power and Energy Soc. General Meeting, 2011, pp. 1–9.[3] M. Vaiman et al., “Risk assessment of cascading outages: methodologies and challenges,” IEEE Trans. Power Syst., vol. 27, no. 2, pp. 631–641, May 2012.[4] I. Dobson, B. A. Carreras, V. E. Lynch, and D. E. Newman, “Complex systems analysis of series of blackouts: cascading failure, critical points, and self-organization,” Chaos: Interdisciplinary J. Nonlinear Sci., vol. 17, no. 2, p. 026103, 2007.[5] M. Eppstein and P. Hines, “A ‘random chemistry’ algorithm for identifying collections of multiple contingencies that initiate cascading failure,” IEEE Trans. Power Syst., vol. 27, no. 3, pp. 1698–1705, Aug. 2012.[6] “Trapezoidal Rule,” Math24, 30-Apr-2020. [Online]. Available: https://www.math24.net/trapezoidal-rule/. [Accessed: 07-Jan-2021].[7] P. Hines, J. Apt, and S. Talukdar, “Large blackouts in North America: historical trends and policy implications,” Energy Policy, vol. 37, no. 12, pp. 5249–5259, 2009.[8] B. A. Carreras, D. E. Newman, I. Dobson, and N. S. Degala, “Validating OPA with WECC data,” in 2013 46th Hawaii Int. Conf. on System Sciences (HICSS), Jan. 2013, pp. 2197–2204.[9] R. Fitzmaurice, E. Cotilla-Sanchez, and P. Hines, “Evaluating the impact of modeling assumptions for cascading failure simulation,” in Proc. IEEE Power Energy Soc. General Meeting, Jul. 2012, pp. 1–8.[10] D. Deka and S. Misra, “Learning for DC-OPF: Classifying active sets using neural nets,” 2019 IEEE Milan PowerTech, Milan, Italy, 2019, pp. 1-6.[11] H.Zhu, “Lecture Note - Ch 06”, The University of Texas at Austin, Austin, TX, EE 369: POWER SYSTEMS ENGINEERING Course, Fall 2019",
        "url": "//research/energy/2021/01/05/Cascading-Outage-Sim-Dynamic.html"
      }
      ,
    
      "research-energy-2021-01-04-lmi-and-power-sys-html": {
        "title": "LMI and Power Systems",
        "tags": "Energy, Power, LMI",
        "date": "January 4, 2021",
        "author": "",
        "category": "",
        "content": "",
        "url": "//research/energy/2021/01/04/LMI-and-Power-Sys.html"
      }
      ,
    
      "research-mathematics-2021-01-03-gs-html": {
        "title": "Gram–Schmidt Process",
        "tags": "Math, Linear Algebra, Mathematics, ALAFF",
        "date": "January 3, 2021",
        "author": "",
        "category": "",
        "content": "This article was written by referring to the Fall 2020 Numerical Analysis: Linear Algebra Course and the following links.  ALAFF: Gram-Schmidt Orthogonalization  ALAFF Git RepositoryGram–Schmidt ProcessGiven a set of linearly independent vectors $Span({ a_0, … , a_{n-1} } ) \\subset \\mathbb{C}^m$, the Gram-Schimdt process computes a new basis {$q_0, … , q_{n-1}$} that spans the same subspace as the original vectors, i.e. $Span({ a_0, … , a_{n-1} } ) = Span({ q_0, … , q_{n-1} } )$ [1].It should be noted that we would like to have the new basis, ${ q_0, … , q_{n-1} }$, having the following characteristics.  All vectors are unit vectors of length 1, i.e. $|q_i| = 1$.  All vectors are mutually perpendicular, i.e. $q_i \\perp q_j$ where $i \\neq j$.These characteristics can be obtained through the following routine which is composed by three steps [1]:  &lt;Gram-Schmidt Process&gt;  Step 1. Compute the direction of the vectors.  Step 2. Compute the magnitude of the normalizer.  Step 3. Compute a unit vector.    Compute the vector $q_0$ ($i=0$)          Step 1. Compute the direction of the vectors.    \\[N.A. \\ (q_0 \\parallel a_0)\\]          Stpe 2. Compute the magnitude of the normalizer.    \\[\\rho_{0, 0}=\\|a_0\\|_2\\]          Step 3. Compute a unit vector.    \\[q_0=a_0/\\rho_{0, 0}\\]          Result    \\[a_0=q_0\\rho_{0, 0}\\]    Compute the vector $q_1$ ($i=1$)          Step 1. Compute the direction of the vectors.    \\[\\rho_{0, 1}=q_0^{H}a_1\\]\\[a_{1}^{\\perp}=a_1-\\rho_{0, 1}q_0\\]          Step 2. Compute the magnitude of the normalizer.    \\[\\rho_{1, 1}=\\|a_1^\\perp\\|_2\\]          Step 3. Compute a unit vector.    \\[q_1=a_1^\\perp/\\rho_{1, 1}\\]          Result    \\[\\left[\\begin{array}{c|c}a_{0} &amp; a_{1}\\end{array}      \\right]=      \\left[\\begin{array}{c|c}q_{0} &amp; q_{1}\\end{array}      \\right]      \\left[\\begin{array}{c|c}      \\rho_{0, 0} &amp; \\rho_{0, 1} \\\\      \\hline      0 &amp; \\rho_{1, 1}      \\end{array}      \\right]\\]    Compute the vector $q_2$ ($i=2$)          Step 1. Compute the direction of the vectors.    \\[\\begin{bmatrix}\\rho_{0, 2} \\\\ \\rho_{1, 2}\\end{bmatrix}=\\begin{bmatrix}q_{0} &amp; q_{1}\\end{bmatrix}^Ha_2\\]\\[a_{2}^{\\perp}=a_2-\\begin{bmatrix}q_{0} &amp; q_{1}\\end{bmatrix}\\begin{bmatrix}\\rho_{0, 2} \\\\ \\rho_{1, 2}\\end{bmatrix}\\]          Step 2. Compute the magnitude of the normalizer.    \\[\\rho_{2, 2}=\\|a_2^\\perp\\|_2\\]          Step 3. Compute a unit vector.    \\[q_2=a_2^\\perp/\\rho_{2, 2}\\]          Result    \\[\\left[\\begin{array}{c|c}a_{0} \\ a_{1}&amp; a_{2}\\end{array}      \\right]=      \\left[\\begin{array}{c|c}q_{0} \\ q_{1} &amp; q_{2}\\end{array}      \\right]      \\left[\\begin{array}{cc|c}      \\rho_{0, 0}  &amp; \\rho_{0, 1} &amp; \\rho_{0, 2} \\\\      0 &amp; \\rho_{1, 1} &amp; \\rho_{1, 2}\\\\      \\hline      0 &amp; 0 &amp; \\rho_{2, 2}      \\end{array}      \\right]\\]    keep do the routine till $i=n-1$          Step 1. Compute the direction of the vectors.      Step 2. Compute the magnitude of the normalizer.      Step 3. Compute a unit vector.      Final Result      \\[A = QR\\]What we should pay attention to in the final result ($A = QR$) are …  All column vectors of $Q$, the new basis {$q_0, … , q_{n-1}$}, are unit vector and mutually orthogonal, which means $Q$ is an unitary matrix.    The matrix $R$ is upper triangular matrix and $rank(R)=m$.    The dot product of $Q$ and $R$, which is equal to $A$, can be regarded as a linear combination of $Q$’s column vectors.    The result of Gram-Shmidt Process can be regarded as a result of QR factorization (decomposotion).  Classical Gram-Schmidt (CGS)The content discussed in the previous section can be summarized into an algorithm as follows, which is the CGS-QR algorithm [2].Consider $A=QR$.Partition the given matrices as follows.\\[\\left[\\begin{array}{c|cc}A_{0} &amp; a_{1} &amp; A_{2}\\end{array}        \\right]=        \\left[\\begin{array}{c|cc}Q_{0} &amp; q_{1} &amp; Q_{2}\\end{array}        \\right]        \\left[\\begin{array}{c|cc}        R_{0, 0}  &amp; r_{0, 1} &amp; R_{0, 2} \\\\        \\hline        0 &amp; \\rho_{1, 1} &amp; r_{1, 2}^T\\\\        0 &amp; 0 &amp; R_{2, 2}        \\end{array}        \\right]\\]Assume that $Q_0$ and $R_{0,0}$ have already been computed.Since $Q$ is unitary matric ($Q_0^HQ_0=I$ and $Q_0^Hq_1=0$),  $Q_0^Ha_1=Q_0^HQ_0r_{0,1}+q_1\\rho_{1,1}=r_{01}$Compute $r_{0,1}$, which is already known.  $r_{0,1}:=Q_0^Ha_1$Compute $a_1^\\perp$ and $\\rho_{1,1}$ (Step 1. &amp; 2.).  $a_1^\\perp:=a_1-Q_0r_{0,1}$  $\\rho_{1,1}:=|a_1^\\perp|$Compute $q_1$ (Step 3.).  $q_1 := a_1^\\perp / \\rho_{1,1}$Figure 1. shows Classical Gram-Schmidt algorithm for computing the QR factorization of a matrix A. The algorithm used FLAME notation.Code 1. shows the algorithms in python language.   Figure 1. Classical Gram-Schmidt algorithm for computing the QR factorization of a matrix A [2]     Code. 1: CGS QR in python  Test_CGS_QR.ipynbModified Gram-Schmidt (MGS)Gram-Schmidt process can be performed differently from CGS, and the corresponding algorithm is as follows, which is called Modified Gram-Schmidt (MGS) [3].Consider $A=QR$.Partition the given matrices as follows.\\[\\left[\\begin{array}{c|cc}A_{0} &amp; a_{1} &amp; A_{2}\\end{array}        \\right]=        \\left[\\begin{array}{c|cc}Q_{0} &amp; q_{1} &amp; Q_{2}\\end{array}        \\right]        \\left[\\begin{array}{c|cc}        R_{0, 0}  &amp; r_{0, 1} &amp; R_{0, 2} \\\\        \\hline        0 &amp; \\rho_{1, 1} &amp; r_{1, 2}^T\\\\        0 &amp; 0 &amp; R_{2, 2}        \\end{array}        \\right]\\]Assume that $a_1$ and $A_2$ are known.Compute $\\rho_{1,1}$ (compute the magnitude ↔︎ Step 2.).  $\\rho_{1,1}:=|a_1|$Compute $q_1$ (compute the unit vector ↔︎ Step 3.).  $q_1:=a_1/\\rho_{1,1}$Compute $r_{0,1}^T$, which is already known.  $r_{0,1}^T:=q_1^H(A_2 - Q_2R_{22}) = q_1^HA_2$Compute $A_2$ (update $A_2$ for the orthogonality ↔︎ Step 1.).  $A_2:=A_2-q_1r_{0,1}^T$Figure 2. shows Modified Gram-Schmidt algorithm for computing the QR factorization of a matrix A. The algorithm used FLAME notation.Code 2. shows the algorithms in python language.   Figure 2. Alternative Modified Gram-Schmidt algorithm for computing the QR factorization of a matrix A [3]     Code. 2: MGS QR in python  Test_MGS_QR.ipynbWhy do we need this?Through Gram-Schmidt process, we can obtain an orthonormal basis of the matrix $A$’s subspace, which has a set of lineary independent vectors {$a_0, …, a_{n-1}$}.The advantages of being able to have an orthonormal basis are following [4].  We can express any  $v \\in \\mathbb{C}^n$ as a linear combination of coefficients, which will allows us to have an explicit formula expressing $v$ with the orthonormal basis.    The explicit formula is very useful when dealing with projection onto subspace.  References[1] M. M. Robert van de Geijn, “Advanced Linear Algebra: Foundations to Frontiers,” ALAFF Classical Gram-Schmidt (CGS). [Online]. Available: https://www.cs.utexas.edu/users/flame/laff/alaff/chapter03-classical-gram-schmidt.html. [Accessed: 03-Jan-2021].[2] M. M. Robert van de Geijn, “Advanced Linear Algebra: Foundations to Frontiers,” ALAFF Classical Gram-Schmidt algorithm. [Online]. Available: https://www.cs.utexas.edu/users/flame/laff/alaff/chapter03-cgs-algorithm.html. [Accessed: 03-Jan-2021].[3] M. M. Robert van de Geijn, “Advanced Linear Algebra: Foundations to Frontiers,” ALAFF Modified Gram-Schmidt (MGS). [Online]. Available: https://www.cs.utexas.edu/users/flame/laff/alaff/Modified-Classical-Gram-Schmidt.html. [Accessed: 03-Jan-2021].[4] Michael Albanese, “Why is orthogonal basis important?,” Mathematics Stack Exchange. [Online]. Available: https://math.stackexchange.com/questions/518600/why-is-orthogonal-basis-important. [Accessed: 03-Jan-2021].",
        "url": "//research/mathematics/2021/01/03/GS.html"
      }
      ,
    
      "research-cs-2021-01-01-virtualenv-html": {
        "title": "(Python-Dev Tips) Virtual Environment",
        "tags": "CS, Dev, Python, virtualenv, Anaconda",
        "date": "January 1, 2021",
        "author": "",
        "category": "",
        "content": "In this article, we are going to explain what is virtual environment in python and why do we need it. Also, we will show you how to set up a virtual environment and introduce basic commands.This posting is one of a series of tips for developing python following the previous post.  Git Basic  Virtual Environment  PEP8  JupyterThis post was written with reference to the following materials.  Python Docs: Virtual Environments  Real Python: Python Virtual EnvironmentsWhat is Virtual-Env &amp; Why Do We Need it?Python virtual environment is an isolated environment for a Python project. This allows each project can have its own dependencies, regardless of what dependencies every other project has [1].This provides the advantage of being able to build each development environment for multiple projects on one local PC. For an example, Figure 1. shows how one can manage virtual environments for serveral projects. More specifically, it shows how to manage each python projection for a web app that uses a different version of the Django package.   Figure 1. Examples of Python Virtual Environment [2].  Basic Virtual-Env UsagesThere are two ways to set up and manage virtual envoronment, pip and anaconda. In this article, we will explain how to set up and manage virtual envoronment using anaconda.Anaconda is a package manager, an environment manager, a Python/R data science distribution, and a collection of over 7,500+ open-source packages [3]. Through this, we can set up and manage a virtual emvironment for each projects.We will introduce basic anaconda usages. For more details, you can refer to the following Documentation or Cheat-Sheet.  Anaconda Documentation  Conda Cheat-SheetWe can create a new virtual environment with the following commands and manage packages in the corresponding virtual environment for each project.  Create a new virtual environmnet        $ conda create --name ENVNAME        Activate a named environment        $ conda activate ENVNAME        Install a package        $ conda install PKGNAME        Deactivate current environment        $ conda deactivate ENVNAME      And, we can clearly provide the dependency for the project to other developers through the following commands.  Exporting the envname.yml        $ conda env export --name ENVNAME &gt; envname.yml      Finally, we can create a virtual environment that matches the developer’s development environment on our local PC through the envname.yml.  Creating an environment from an envname.yml        $ conda env create --file envname.yml      Reference[1] Real Python, “Python Virtual Environments: A Primer,” Real Python, 17-Jul-2020. [Online]. Available: https://realpython.com/python-virtual-environments-a-primer/. [Accessed: 05-Jan-2021].[2] S. Shakya, “Virtual Environment in Python,” Medium, 02-May-2019. [Online]. Available: https://medium.com/incwell-bootcamp/virtual-environment-in-python-54db665b9939. [Accessed: 05-Jan-2021].[3] “Anaconda Individual Edition¶,” Anaconda Individual Edition - Anaconda documentation. [Online]. Available: https://docs.anaconda.com/anaconda/. [Accessed: 05-Jan-2021].",
        "url": "//research/cs/2021/01/01/virtualenv.html"
      }
      ,
    
      "daily-essay-2020-12-28-how-to-speak-html": {
        "title": "(TIL) How to Speak",
        "tags": "Essay, Today I Learned",
        "date": "December 28, 2020",
        "author": "",
        "category": "",
        "content": "How to Speak: 7 Speaking Tips from Patrick Henry WinstonHow To Speak by Patrick WinstonHow to Speak - The Big Four",
        "url": "//daily/essay/2020/12/28/how-to-speak.html"
      }
      ,
    
      "research-energy-2020-12-14-emtp-line-cable-modeling-html": {
        "title": "(Tutorial) EMTP - Line/Cable Modeling for EMT Simulations",
        "tags": "Energy, Power, EMTP",
        "date": "December 14, 2020",
        "author": "",
        "category": "",
        "content": "  EMTP Tutorials",
        "url": "//research/energy/2020/12/14/EMTP-Line-Cable-Modeling.html"
      }
      ,
    
      "research-mathematics-2020-12-13-prob-html": {
        "title": "(TIL) Reviewing Statictics and Probability",
        "tags": "Math, Statictics, Probability, Mathematics",
        "date": "December 13, 2020",
        "author": "",
        "category": "",
        "content": "",
        "url": "//research/mathematics/2020/12/13/prob.html"
      }
      ,
    
      "daily-essay-2020-12-12-essay-html": {
        "title": "Laïcité",
        "tags": "Essay, Sharing My Thought",
        "date": "December 12, 2020",
        "author": "",
        "category": "",
        "content": "Recently, I have finished two final exams, and one left next Thursday. I think it is a good moment to start again to write what I have been thinking these days. Looking back at the end of the semester, I realized that a lot had happened globally, which I have not thought deeply about due to my hectic school life. For instance, the pandemic broke out, and we are living in the era of New Normal. Also, there was a presidential election in the US. In my thought, these are the most notable or significant events of this year. However, in this article, I would like to share my view about what happened in France.   (https://bdidier.fr/4eme-la-laicite/)  In October, a French middle school teacher was attacked and beheaded by a terrorist. Similar incidents have been happening after this incident, and it reminded me of the terror in Paris four years ago. Behind these tragedies, we all know there are complex religious problems. Several factors may be responsible for the continued occurrence of these incidents in France. In my respect, it has a lot to do with Laicite (Secularism).I know that it is nearly impossible for me, not French, to fully understand and describe the meaning of Laicite. To the best of my understanding, it means strict separation of religion from society, the secular world. There must be pros and cons of separating religion from our lives. I can agree that we can get an opportunity to consider religion on an equal footing with other values by taking it apart from society. For example, in Korea, many parents agree that their children can make decisions for their future by themselves. However, suddenly they change extremely conservative when it comes to religious choices, which is nonsense, given that it is just another decision like others. I think they act differently because they never take apart religion from their lives and always give a top priority to it. Suppose parents had tried to separate religion from society and consider it on an equal footing. In that case, they might have different conversations with their children and ended up with more rational conclusions.However, a series of these thoughts can be taken as a challenge or blasphemy for violent and radical religious groups. In my opinion, these groups are very likely to use violence in the form of retaliation when society becomes unstable. As a result, ironically, the society where rational judgment can be made is exposed to the risk of terror. As far as religion is concerned, I think France has a society with good conditions for making rational judgments. Simultaneously, the country is exposed to violence in an unstable period due to the pandemic. I hope they will overcome this crisis well without further tragedy, and others will be able to learn the unique way of their thinking.",
        "url": "//daily/essay/2020/12/12/essay.html"
      }
      ,
    
      "research-cs-2020-10-01-git-tips-html": {
        "title": "(Python-Dev Tips) Git Basic",
        "tags": "CS, Dev, Git",
        "date": "October 1, 2020",
        "author": "",
        "category": "",
        "content": "Starting with this posting, we will upload a series of articles that can help with Python development. The series will be written in four articles, and the contents are as follows, and if necessary, additional posts will be uploaded as a separate series.In this article, we will show you what Git is and Why do we need it. Also, we will give a brief intro to how we can start and use Git.  Git Basic  Virtual Environment  PEP8  JupyterWhat is GitGit is a free and open-source distributed version control system designed to handle everything from small to very large projects with speed and efficiency [1]. It provides us a history of content changes and facilitates collaborative changes to files [2].   Figure 1. Examples of Using Git [3].  Why Do We Need GitWhen we work on a project and do something creative and productive, we repeat the following four steps [2].  Create things.  Save things.  Edit things.  Save the things again.By repeating the above steps, we add new things, delete unnecessary ones, request modifications, and make corrections where necessary. To make this process straightforward and efficient, we turn to the help of version control. Through the version control system, we can easily track the followings [2].  When we did it.  Why we did it.  What the contents of the change.This makes it possible to efficiently understand the project’s process and be more productive when revisiting the project in the future.For these reasons, we cannot overemphasize the necessity of version control when working on projects through collaboration as well as personal projects. By using Git, we can take these benefits of version control.   Figure 2. Workflow with Git [4].  Basic Git CommandsThe following are essential terminal commands for Git. It may be difficult to memorize, but it is good to understand only its purpose. As long as you understand each command’s purpose, you can easily use Git through a GUI, which will be covered in the following section.For reference, the contents are referred to as the following links.  Essential git commands every developer should know  Top 20 Git Commands With Examplesgit init$ git init [project-name]  This command is used to start a new repository.git clone$ git clone [url]  This command is used to obtain a repository from an existing URL.git add$ git add [file-name]  This command adds a file to the staging area.git rm$ git rm [file-name]  This command deletes the file from your working directory and stages the deletion.git commit$ git commit -m “Message to go with the commit here”  This command records or snapshots the file permanently in the version history.git status$ git status  This command lists all the files that have to be committed.git push$ git push [variable name] master  This command sends the committed changes of master branch to your remote repository.$ git push [variable name] [branch-name]  This command sends the branch commits to your remote repository.git branch$ git branch  This command lists all the local branches in the current repository.$ git branch [branch-name]  This command creates a new branch.$ git branch -d [branch-name]  This command deletes the feature branch.git checkout$ git checkout [branch-name]  This command is used to switch from one branch to another.$ git checkout -b [branch-name]  This command creates a new branch and also switches to it.git pull$ git pull [repository link]  This command fetches and merges changes on the remote server to your working directory.git merge$ git merge [branch-name]  This command merges the specified branch’s history into the current branch.git diff$ git diff  This command shows the file differences which are not yet staged.$ git diff [first branch-name] [second branch-name]  This command shows the differences between the two branches mentioned.git stash$ git stash save  This command temporarily stores all the modified tracked files.$ git stash pop  This command restores the most recently stashed files.$ git stash list  This command lists all stashed changesets.$ git stash drop  This command discards the most recently stashed changeset.GitKrakenThere is an entry barrier to use the commands described above in a terminal window. For those who have difficulty using Git in a terminal window, we suggest to use a GUI called GitKraken. With GitKraken, you can intuitively and easily manage projects without memorizing all the git commands. Figure 3. is a screenshot of GitKraken.We can do the basic operation as the git commands described above through the buttons in Area 1.In Area 2, GitKraken shows the files that have been modified compared to the log, whether these files are added in the staging area, and allows us to commit.Lastly, in Area 3, it shows us the workflow of the project.   Figure 3. GitKraken Screenshot.  One More Thing 😜Those who want to use Git only with commands in a terminal window, not using a GUI, or who want to have a deeper understanding, can learn without losing interest through the quest-game-type tutorial provided at the following link.  Git Tutorial Quest Game   Figure 4. Git Command Line Tutorial Screenshot.  Reference[1] Git. [Online]. Available: https://git-scm.com/. [Accessed: 01-Oct-2020].[2] “Git Basics Episode 1,” Git. [Online]. Available: https://git-scm.com/video/what-is-version-control. [Accessed: 01-Oct-2020].[3] S. C. Atuonwu, “5 Git Commands You Should Know, with Code Examples,” freeCodeCamp.org, 10-Jun-2020. [Online]. Available: https://www.freecodecamp.org/news/5-git-commands-you-should-know-with-code-examples/. [Accessed: 01-Oct-2020].[4] Atlassian, “Gitflow Workflow: Atlassian Git Tutorial,” Atlassian. [Online]. Available: https://www.atlassian.com/git/tutorials/comparing-workflows/gitflow-workflow. [Accessed: 01-Oct-2020].",
        "url": "//research/cs/2020/10/01/git-tips.html"
      }
      ,
    
      "daily-essay-2020-08-18-essay-html": {
        "title": "The shape of someone or something that I love",
        "tags": "Essay",
        "date": "August 18, 2020",
        "author": "",
        "category": "",
        "content": "Whenever I come back to Korea, 떡볶이 has always been the first food that I had. Briefly speaking, this food is just some rice cakes with spicy sauce. Compare to other Korean foods, 떡볶이 might seem shabby. However, this food is one of the reasons why I love and how I remember this place. Why did I pick 떡볶이 instead of other fancy dishes, and why am I so into it? I guess this is because it is my unique way of engraving memories in this country.Likewise, most people who have not grown up in this country might come up with great landmarks when they imagine Korea. However, as a born and raised person in Korea, the shape of this country in my heart is not like that. It could be the small marketplace in my old hometown, or it could be the parking lot in front of my apartment building, where I used to ride a bike and roller skates. It is kind of a secret between me and the place that I love.This pattern is identically applied to the people around me. The one who I love (or loved) is not remembered as her bright and shining moments that all the others could have seen. I memorized her in a way that no one could imagine. It does not have to be pretty or lovely. It just needs to be my little secret between her and me. These secrets comfort me and give strength, even though I can no longer be together with her.",
        "url": "//daily/essay/2020/08/18/essay.html"
      }
      ,
    
      "research-mathematics-2020-07-21-geometric-meaning-of-hessian-html": {
        "title": "Geometric Meaning of Hessian Matrix",
        "tags": "Math, Linear Algebra, Mathematics",
        "date": "July 21, 2020",
        "author": "",
        "category": "",
        "content": "Starting with the definition of the Hessian Matrix, this posting will focus on the geometric meaning of the Hessian matrix. Also, we will discuss the eigenvalues and eigenvectors of the Hessian and introduce the application of it.This post was written with reference to the following materials.  Donghoon Yeo’s blog posting  Wikipedia &gt; HessianHessian MatrixDefinitionIn mathematics, the Hessian matrix or Hessian is a square matrix of second-order partial derivatives of a scalar-valued function, or scalar field. It describes the local curvature of a function of many variables. [1]Suppose $f : ℝ^n → ℝ$ is a function taking as input a vector $x ∈ ℝ^n$ and outputting a scalar $f(x) ∈ ℝ$. If all second partial derivatives of $f$ exist and are continuous over the domain of the function, then the Hessian matrix $H$ of $f$ is a square n×n matrix, usually defined and arranged as follows; [1]   Figure 1. Definition of Hessian matrix. [1]  Geometric MeaningFirst of all, it is well known that all matrices can be considered as linear transformations. Likewise, we can think of a Hessian matrix as a linear transformation. Geometrically, the main feature of the linear transformation performed by the Hessian matrix is to make a given function more convex or concave.Let’s look at the Hessian’s geometric meaning in detail through examples.The Hessian matrices corresponding to Figure 2 and 3 are as follow;\\[\\begin{bmatrix}2 &amp; 1\\\\1 &amp; 2\\\\\\end{bmatrix} and \\begin{bmatrix}2 &amp; 0\\\\0 &amp; -2\\\\\\end{bmatrix}.\\]The things to note here are, the eigenvectors of the Hessian matrix represent the principal axis of transformation and the eigenvalues represent the degree of transformation. More specifically, if the eigenvalues are all positive (Figure 2), it makes the given function more convex. Conversely, if the eigenvalues are all negative, it makes the given function more concave. However, if some of the eigenvalues are positive, and some are negative (Figure 3), the given function is converted to a saddle shape. To recapitulate, by using the main feature of the geometric transformation shown by the Hessian, we could emphasize the gradient change of the given function.   Figure 2. Example of Hessian transform making the given function more convex. [2]     Figure 3. Example of Hessian transform making the given function to a saddle shape function. [2]  ApplicationsUsing the feature that the Hessian emphasizes the gradient change, it can be used as a filter that detects the contour (edge) of a specific object in a given image, which is considered as a function at this point. Figure 4 shows the description of edge detection and the Hessian’s eigenvalues, and Figure 5 shows an application detecting the vessel using the Hessian.   Figure 4. Edge detection using Hessian's eigenvalues [3]     Figure 5. Hessian's applicaiton: Frangi filter for vessel detection. [2]  References[1] “Hessian matrix,” Wikipedia, 24-Jun-2020. [Online]. Available: https://en.wikipedia.org/wiki/Hessian_matrix. [Accessed: 21-Jul-2020].[2] Y. D. Yeo, “Geometrical meaning of Hessian Matrix,” 17-Jun-2020. [Online]. Available: https://angeloyeo.github.io/2020/06/17/Hessian.html. [Accessed: 21-Jul-2020].[3] “Hessian Matrix of the image,” Stack Overflow, 01-Sep-1963. [Online]. Available: https://stackoverflow.com/questions/22378360/hessian-matrix-of-the-image. [Accessed: 21-Jul-2020].",
        "url": "//research/mathematics/2020/07/21/geometric-meaning-of-hessian.html"
      }
      ,
    
      "research-ml-dl-2020-07-20-how-to-choose-layer-html": {
        "title": "(TF) Which Layer Do I Need?",
        "tags": "ML&DL, MNIST, CNN, RNN",
        "date": "July 20, 2020",
        "author": "",
        "category": "",
        "content": "The structure of the deep learning model is designed differently depending on the types of data features and the objective of the model. More specifically, in order to select the type of layer used in the model, the characteristics of data features and the learning objectives of the model must be considered.In order to find out which structure is most suitable, we experimented with fixing the type of dataset and the target of the model and changing the structure of the model. The dataset used in the experiment is MNIST. The types of models used in the experiment were as follows; DenseNet using only dense layer, ConvNet using convolutional layer, and LstmNet using LSTM layer.Full code of the experiments can be found at the following github repository.  Park’s GitHub &gt; How to choose layerThis post was written with reference to the following materials.  Aymeric Damien’s GitHub &gt; Neural Network Example  Aymeric Damien’s GitHub &gt; Convolutional Neural Network Example  Irhum Shafkat’s Medium posting &gt; Intuitively Understanding Convolutions for Deep Learning  Aymeric Damien’s GitHub &gt; Recurrent Neural Network Example  Simplilearn &gt; Recurrent Neural Network Tutorial  Park’s SlideShare &gt; Understanding LSTMModel StructuresDense ModelThis model consisted only of dense layers. This is the simplest model of the neural network and works well for all types of data, but performance decreases when an input data becomes complicated or large. Therefore, dense layers are used in learning simple data. In addition, in the case of learning complex data, dense layers are used in the last part of the model, which is the stage where features are extracted and get simple enough.  CNN ModelThis model consisted of convolutional layers. This model is suitable when there are spatial relationship across the data. Figure 1 depicts how a convolutional layer works, and it helps understand why this model works well when there are spatial relationship across data.     Figure 1. Visualization of how the convolutional neural network layer works [1].  RNN(LSTM) ModelThis model consisted of LSTM layers. This model is suitable when there are temporal (sequential) relationship across the data. Figure 2 depicts how a LSTM layer works, and it helps understand why this model works well when there are temporal relationship across data.     Figure 2. Visualization of how the recurrent neural network layer works [2].  Experiment ResultAs a result of the experiment, the CNN model using a convolutional layer showed the highest performance for learning MNIST image data. Direct comparison was not possible because the number of trainable parameters differed for each model, but the result was obtained by adjusting hyper-parameters to obtain the best performance for each model.To sum up, we have confirmed that it is best to use a convolutional layer when learning MNIST image data.                   Accuracy      Loss                  DenseNet      0.9556      1.5092              ConvNet      0.9817      1.4793              LstmNet      0.9603      1.5015         Figure 2. Checking the validation result with tensorboard.  Future StudyIn some cases, such as image data or stock data, we can know the nature of the feature data in advance and use the CNN or RNN layers respectively. However, it is difficult to fully understand the charactieristic of completely new feature data. In this case, it is difficult to make assumptions about the temporal/spatial relationships across the data. As a result, it is not easy to decide which layer to use.Transformer is a model designed to solve this problem. Transformer is a model based on attention, it make no assumptions about the temporal/spatial relationships across the data [3]. In the next posting, we will discuss the structure and application of the Transformer.Reference[1]I. Shafkat, “Intuitively Understanding Convolutions for Deep Learning,” Medium, 07-Jun-2018. [Online]. Available: https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1. [Accessed: 23-Jul-2020].[2] A. Biswal, “Recurrent Neural Network Tutorial,” Simplilearn.com, 28-Apr-2020. [Online]. Available: https://www.simplilearn.com/tutorials/deep-learning-tutorial/rnn. [Accessed: 23-Jul-2020].[3] “Transformer model for language understanding : TensorFlow Core,” TensorFlow. [Online]. Available: https://www.tensorflow.org/tutorials/text/transformer. [Accessed: 23-Jul-2020].",
        "url": "//research/ml&amp;dl/2020/07/20/how-to-choose-layer.html"
      }
      ,
    
      "research-ml-dl-2020-07-19-pytorch-basic-structure-html": {
        "title": "(PyTorch) Basic Steps for Training a Model",
        "tags": "ML&DL, PyTorch",
        "date": "July 19, 2020",
        "author": "",
        "category": "",
        "content": "PyTorch is one of the most well-known deep learning frameworks as well as Tensorflow. This posting will describe the basic steps for traing a model with PyTorch. Briefly, the basic steps of how to train a model are as follow.  Load &amp; pre-process the dataset  Set a model  Set an optimizer &amp; a loss function  Train the model  Evaluate the modelFull code can be found at the following github repository.  Park’s GitHub &gt; Basic Structure of Training a ModelThis post was written with reference to the following materials.  JiHyung Moon’s Meduim Posting  PyTorch official webpage &gt; Tutorials &gt; Visualizing Models, Data, and Training with TensorBoard1. Load &amp; pre-process the datasetWe used the FashionMNIST dataset for the experiment. The dataset can be downloaded through torchvision.datasets, and preprocessing can be performed through transforms.Compose.  2. Set a modelWe constructed a simple convolutional neural network model.  3. Set optimizer &amp; loss functionWe set the optimizer and loss function to train the model constructed in the previous step. The optimizer and loss function types were selected according to the type of the features of the given input data and the purpose of the model.  4. Train the modelIn order to train a model, we must follow the following 5 steps.  initialize the gradient  forward propagation  calculate the loss  backward propagation  optimize (update) the weights based on forward &amp; backward propagation  5. Evaluate the modelWe used the validation dataset to measure the performance of the completed training model. Note that the evaluate process is very similar to the training process. However, in the evaluate process, torch.no_grad() is required because the weights must never change.  ",
        "url": "//research/ml&amp;dl/2020/07/19/pytorch-basic-structure.html"
      }
      ,
    
      "research-ml-dl-2020-07-18-tf-basic-structure-html": {
        "title": "(TF) Basic Steps for Training a Model",
        "tags": "ML&DL, Tensorflow",
        "date": "July 18, 2020",
        "author": "",
        "category": "",
        "content": "TesorFlow is one of the most well-known deep learning frameworks. This posting will describe the basic steps for training a model with Tensorflow. Briefly, the basic steps for how to train a model through TensorFlow are as follow.  Load &amp; pre-process the dataset  Set a model  Compile the model : set an optimizer, a loss function, &amp; metrics  Fit the model  Evaluate the modelFull code can be found at the following github repository.  Park’s GitHub &gt; Basic Structure of Training a ModelThis post was written with reference to the following materials.  TensorFlow official website &gt; TensorFlow 2 quickstart for beginners  TensorFlow official website &gt; TensorFlow 2 quickstart for experts  TensorFlow official website &gt; Get started with TensorBoard1. Load &amp; pre-process the datasetFor the experiment to show the basic process of training a model with TensorFlow, we used the MNIST dataset. The given images are a grayscale, so we need a preprocessing process to scale the image data features from 0 to 1.  2. Set a modelIn this step, we designed the structure of a model. The model in this experiment was relatively simple, so it could be easier to construct the model using tf.keras.Sequential. However, we use custumized model for the experiment. This is because a custumized model must be used when constructing a more complex model in the future, and it is necessary to become familiar with it. More specifically, in case of the model becomes complicated and the input features do not flow sequentially, the model must be constructed in a custum manner. Transformer model is a good example.  (optional) Set callbackscheckpointWe set checkpoint callback to record the training process of the model.  tensorboardWe set tensorboard callback to visualize the training process and strucutre of the model.  reduce learning rateWe set reduce-learning-rate callback for better training result of the model.  3. Compile the modelSet optimizer, loss function, &amp; metricsAfter constructing the model, you need to set the learning process by calling the compile method. Compile method has three important parameters; optimizer, loss, and metrics.The optimizer sets up the training process. The loss sets the loss function to be minimized during the optimization process. The metrics are used to monitor training. These should be set differently depending on the type of feature data and the purpose of the model.The model was compiled using the set optimizer, loss, and metrics.     4. Fit the modelWe conducted training using the preprocessed dataset and the compiled model.  (Optional) Check the training process via tensorboardThrough the tensorboard callback set in the previous step, we visualized the training process and the model graph. Figure 1 shows the training process of the model.     Figure 1. Checking the training process with tensorboard.  (Optional) Load the best weightsThrough the checkpoint callback set in the previous step, we loaded the weights showing the best performance.  5. Evaluate the modelAs a final step, we evaluated the performance of the model using the test dataset.  ",
        "url": "//research/ml&amp;dl/2020/07/18/tf-basic-structure.html"
      }
      ,
    
      "research-ml-dl-2020-06-01-mnist-html": {
        "title": "(TF &amp; PyTorch) MNIST tutorial",
        "tags": "ML&DL, MNIST",
        "date": "June 1, 2020",
        "author": "",
        "category": "",
        "content": "MNIST is the set of data for training the machine to learn handwritten numeral images, which is the most popular and appropriate subject for the purpose of entering deep learning.Through this posting, piece of codes with explanation will be provided and full codes are upload on the following links;  MNIST code-TF ver.ipynb  MNIST code-PyTorch ver.ipynbAlso, this post is written with reference to the following sources;  Tensorflow 2 quickstart for experts  PyTorch &gt; Tutorials &gt; Neural Networks  FastCampus &gt; DeepLearningLectureTensorflow version1. Exploratory Data Analysis (EDA)In order to train a deep learning model, the first thing to do is to explore and analyze the given dataset. In this stage, we can get some hints for designing a structure of the model. The things we have to check in EDA are following;First we need to check size and shape of feature data and target data. Based on the result, we can confirm that a proper shape of input &amp; output data for our model; Input data shape is 28 by 28 matrix (or tensor) and output is a scalar.  Second, we we have to check the value of target data. Since the target data is discrete, we can confirm that the model will be a classification model, and we will refer target as label from now on. Also, we need to check whether the distribution of labels in train and test dataset is biased or not. If dataset is biased, the model trained with this dataset will also biased. This is one of the main reason why we need to check and analyze the given dataset before build and train the model.     Figure 1. Distribution of label dataset  (Optional) Check the real image of feature data. Checking how the feature data looks like is not necessary in training and evaluating the model. However, this will allows you intuitive understanding for analyzing dataset and designing a structure of the model.     Figure 2. Plot a real image of feature dataSample image of feature data  2. Data preprocessFirst, the given dataset need to be reshaped properly. In this step, feature data need an additional dimension to use convolution layers. Also, label data need to be reshaped label encoding into one-hot-encoding for a classification model [1].Second, feature data have to be normalized [2]. Through this process, all features data are scaled to a same unit preventing from one feature dominate others.Lastly, we will use batch to control stability of the training [3]. Also, data distribution of each batches might occur bias, so train data need to be shuffled before split into batches. It is worth noting at this step that Tensorflow provides a nice feature called tf.Data to help organize the given data.  3. ModelThe model is comprised of two parts, feature extraction and classification. In the feature extraction stage, the model use two dimension convolution filter (Conv2D) since the input feature data is image data. Addition to Conv2D, rectified linear unit (ReLU), pooling and dropout unit [4] are used. In classification stage, a fully connected network (FCN) is used. Also, softmax function is attached at the end of the FCN which give us probabilities for each class label.  (Optional) Visualization of the model’s layersConv2D     Figure 3. Visualzation of the Conv2D layer's Input and Output.       Figure 4. Visualzation of the Conv2D layer's Output Values Distribution, Weights, and the Output Value.  Activation     Figure 5. Visualzation of the activation (ReLU) layer's Output Values Distribution and the Output Value  Pooling     Figure 6. Visualzation of the Pooling layer's Output Values Distribution and the Output Value  Fully Connected  4. GraphTraining a model requires proper loss object and optimizer. Also, we should set up graphs that can execute train step and test step using loss object and optimizer. In train step, we deploy the loss object to calculate the losses and optimizer to adjust weights variables. In test step, we implement loss object to clalulate the performance of the model and no optimizer.  5. Train &amp; EvaluateWe can train the model and check the performance using the dataset and graphs prepared in the previous process.  PyTorch version1. EDAEDA is skipped because it is similar to the process performed using Tensorflow.2. Data preprocess  3. Model  (Optional) Explanation of the model’s layersConv2d     Figure 7. Visualzation of the Conv2d layer's Input, Weights, and Output.  Pooling     Figure 8. Visualzation of the Pooling layer's Input and Output.  Fully Connected  4. Train &amp; Evaluate  References[1] A. J. SpiderCloud Wireless, “Why using one-hot encoding for training classifier,” LinkedIn. [Online]. Available: https://www.linkedin.com/pulse/why-using-one-hot-encoding-classifier-training-adwin-jahn. [Accessed: 26-Oct-2019].[2] U. Jaitley, “Why Data Normalization is necessary for Machine Learning models,” Medium, 09-Apr-2019. [Online]. Available: https://medium.com/@urvashilluniya/why-data-normalization-is-necessary-for-machine-learning-models-681b65a05029. [Accessed: 26-Oct-2019].[3] J. Brownlee, “How to Control the Stability of Training Neural Networks With the Batch Size,” Machine Learning Mastery, 03-Oct-2019. [Online]. Available: https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/. [Accessed: 26-Oct-2019].[4] Hinton, G., Srivastava, N., Krizhevsky, A., Sutskever, I. and Salakhutdinov, R. (2019). Improving neural networks by preventing co-adaptation of feature detectors. [online] arXiv.org. Available at: https://arxiv.org/abs/1207.0580 [Accessed 26 Oct. 2019].[5] A. S. V, “Understanding Activation Functions in Neural Networks,” Medium, 30-Mar-2017. [Online]. Available: https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0. [Accessed: 26-Oct-2019].[6] “Pooling,” Unsupervised Feature Learning and Deep Learning Tutorial. [Online]. Available: http://deeplearning.stanford.edu/tutorial/supervised/Pooling/. [Accessed: 26-Oct-2019].",
        "url": "//research/ml&amp;dl/2020/06/01/mnist.html"
      }
      ,
    
      "research-ml-dl-2019-10-21-dl-intro-html": {
        "title": "(TF &amp; PyTorch) Introduction of becoming adept in DL frameworks",
        "tags": "ML&DL, Deep Learning, Tensorflow, PyTorch",
        "date": "October 21, 2019",
        "author": "",
        "category": "",
        "content": "Due to rapid improvements in computing performance and the amount of data that is accumulated, deep learning is gaining strength. Accordingly, IT Giants develop their deep learning framework to provide developers with a development environment, such as Google’s Tensorflow and Facebook’s PyTorch.   Figure 1. Deep learning frameworks  Each framework has its characteristics and strength, and they are properly used for appropriate purposes. For engineers with research purposes, it is necessary to note Figure 2. According to data from RISELab, the recent trend in the papers uploaded on arXiv.org shows that TensorFlow and PyTorch are mainly used in research purposes. It seems that choosing Tensorflow or PyTorch would be the best choice for people who are planning to dive in deep learning. It will allow understanding other’s research more easily and quickly.   Figure 2. The number of papers posted on arXiv.org that mention each framework. Source: Data from RISELab and graphic by Ben Lorica.  In the future, I will select various topics and upload a series of tutorials, and code will also be uploaded in two versions, Tensorflow and PyTorch. First, I will upload a post about basic topics, such as the MNIST tutorial. After that, I will discuss energy-related time series and reinforcement learning topics, which are my research interests. I hope this will help engineers who are new to using deep learning field or would like to be more adept at dealing with the frameworks.",
        "url": "//research/ml&amp;dl/2019/10/21/dl_intro.html"
      }
      ,
    
      "daily-essay-2019-09-22-essay-html": {
        "title": "What makes me nervous these days",
        "tags": "Essay",
        "date": "September 22, 2019",
        "author": "",
        "category": "",
        "content": "After Two years of working as a researcher at Korea Electronics Technolog Institute, I entered the University of Texas at Austin(UT Austin) as a master’s student. During four months, since I have got an admission offer from UT Austin, people showed different reactions. Some celebrated about entering UT Austin, and others were worried about studying abroad. Former voices, which were louder til I left my home town, become smaller and I got nervous.Everything was going as I planned. The UT Cockrell School of Engineering was one of my dream school, and my registration was also well on it’s well. I had a great time during International Student OT and Department wise OT. Also, I added all the courses I wanted for my first semester. I thought there was no reason for getting nervous or anxious. However, I cannot ignore my anxiety, and it was getting worse as time went by.So I changed my strategy. I started to find out what made me nervous. After a week of figuring out, I found the most plausible reason. It was because of me being impatient with success. It was just a starting point of two years journey. The worst part was that I left the issue after I realized the problem since I did not know how to deal with it.While I was getting tired of this feeling, I read confession of one man which changed my mind. He was a man who just got discharged from the army and trying to settle in where he came from. He said, “I was nervous because I was doing nothing at that time.” At that moment, the words penetrated my heart and made me think, “I should do something, even if it looks not meaningful.” And my answer was to start recording my experience in writing. I believe it allows me to look back at myself and gives me an opportunity to do better next time.This writing is my first step to get rid of my anxiety and improve my school life. Although my first post in UT Austin starts with unfavorable story, I will end up my writing with good news about myself.",
        "url": "//daily/essay/2019/09/22/essay.html"
      }
      
    
  };
</script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.6/lunr.min.js"></script>
<script src="/assets/js/search.js"></script></section>
</article>
  </div>
  


<footer class="site-footer">
	<p class="text">Powered by <a href="https://jekyllrb.com/">Jekyll</a> with <a href="https://github.com/rohanchandra/type-theme">Type Theme</a>
</p>
</footer>


</body>

</html>

<!-- <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      processEscapes: true
    }
  });
  </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"
  type="text/javascript"></script> -->